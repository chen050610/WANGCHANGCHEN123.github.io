<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A7/" class="post-title-link" itemprop="url">爬虫初级</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-01-29 16:17:25 / 修改时间：16:20:49" itemprop="dateCreated datePublished" datetime="2024-01-29T16:17:25+08:00">2024-01-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="爬虫初级"><a href="#爬虫初级" class="headerlink" title="爬虫初级"></a>爬虫初级</h1><h4 id="作者：饭桶晨"><a href="#作者：饭桶晨" class="headerlink" title="作者：饭桶晨"></a>作者：饭桶晨</h4><h4 id="QQ：3445883193"><a href="#QQ：3445883193" class="headerlink" title="QQ：3445883193"></a>QQ：3445883193</h4><h4 id="csdn：翻斗花园突破手胡图图122"><a href="#csdn：翻斗花园突破手胡图图122" class="headerlink" title="csdn：翻斗花园突破手胡图图122"></a>csdn：翻斗花园突破手胡图图122</h4><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230200215985.png" alt="image-20231230200215985"></p>
<h6 id="什么是爬虫？"><a href="#什么是爬虫？" class="headerlink" title="什么是爬虫？"></a>什么是爬虫？</h6><p>通过编写程序，模拟浏览器上网，然后让其去互联网抓取数据的过程。</p>
<h6 id="爬虫的价值："><a href="#爬虫的价值：" class="headerlink" title="爬虫的价值："></a>爬虫的价值：</h6><p>当然是为了提升自己的物质生活或者精神生活。现在经常听到<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%A4%A7%E6%95%B0%E6%8D%AE&spm=1001.2101.3001.7020">大数据</a>时代，哎，数据就是 Money 哦，很少存在数据共享的，这个时候，那我们就得自己靠本事找数据啦。搜寻数据这个过程其实并不想象中的难，每个领域的人都可以利用该技术得到自己想要的</p>
<h6 id="爬虫的合法性？"><a href="#爬虫的合法性？" class="headerlink" title="爬虫的合法性？"></a>爬虫的合法性？</h6><p>1.具有违法风险</p>
<p>2.在法律中是不被禁止</p>
<p>3.窃取后台数据就会违法</p>
<p>4.善意爬虫</p>
<p>5.恶意爬虫：干扰了被访问网站的正常运行，抓去了收到法律保护的特定类型的数据和信息</p>
<h6 id="如何避免？"><a href="#如何避免？" class="headerlink" title="如何避免？"></a>如何避免？</h6><p>1.时常优化程序</p>
<p>2在使用，传播爬到的数据，审查内容</p>
<p>3商业机密等敏感需要及时停止爬取</p>
<h6 id="爬虫的分类"><a href="#爬虫的分类" class="headerlink" title="爬虫的分类"></a>爬虫的分类</h6><p>1.通用爬虫：抓取系统重要组成部分,抓取的是整张页面</p>
<p>2.聚集爬虫：指定的局部内容</p>
<p>3.增量式爬虫：检测网站数据更新的情况。只会抓取更新最新的数据</p>
<h6 id="反爬机制"><a href="#反爬机制" class="headerlink" title="反爬机制"></a>反爬机制</h6><p> 门户网站，可以通过指定相应的技术和策略</p>
<h6 id="反反爬机制"><a href="#反反爬机制" class="headerlink" title="反反爬机制"></a>反反爬机制</h6><p>破解门户网站的反爬机制，从而获取门户网站的信息</p>
<h6 id="robots-txt协议（反反爬机制，君子协议）"><a href="#robots-txt协议（反反爬机制，君子协议）" class="headerlink" title="robots.txt协议（反反爬机制，君子协议）"></a>robots.txt协议（反反爬机制，君子协议）</h6><p>规定那些可以被爬，那些不可以被爬</p>
<p>可以遵从，可以不遵从；</p>
<p>列如</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230202651322.png" alt="image-20231230202651322"></p>
<p>不遵从可能会有法律问题</p>
<h4 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h4><p>概念：服务器和客户端进行数据交互的一种方式。（就比如威虎山里面的黑话）</p>
<h6 id="常用请求头信息"><a href="#常用请求头信息" class="headerlink" title="常用请求头信息"></a>常用请求头信息</h6><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230203119605.png" alt="image-20231230203119605"></p>
<p>这就是请求头（不详解了）</p>
<p>connect是请求完毕以后是保持连接还是断开</p>
<h6 id="响应头信息"><a href="#响应头信息" class="headerlink" title="响应头信息"></a>响应头信息</h6><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230203344976.png" alt="image-20231230203344976"></p>
<p>content-type：服务器返回客户端的数据类型</p>
<h6 id="https协议"><a href="#https协议" class="headerlink" title="https协议"></a>https协议</h6><p>传续的数据进行加密</p>
<h6 id="加密方式"><a href="#加密方式" class="headerlink" title="加密方式"></a>加密方式</h6><p>1：对称加密</p>
<p>加密的钥匙和密文都传过去</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230203648592.png" alt="image-20231230203648592"></p>
<p>2：非对称加密</p>
<p>有私钥和公钥，无法保证客户端拿到的公钥是服务器发来的，有可能人篡改</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231083933191.png" alt="image-20231231083933191"></p>
<p>3：证书密钥加密</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231084340066.png" alt="image-20231231084340066"></p>
<p>保证了客户端的拿到的是服务器端发来的</p>
<h2 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h2><h6 id="网络请求的模块"><a href="#网络请求的模块" class="headerlink" title="网络请求的模块"></a>网络请求的模块</h6><p>1.urllib模块</p>
<p>2.requests模块</p>
<p>主要第二个</p>
<p>概念：基于python原生的一款网络请求的模块</p>
<p>作用：模拟浏览器发送请求</p>
<p>如何使用？</p>
<p>需要遵从浏览器发送请求的方式；（编码流程）</p>
<p>1.指定url</p>
<p>2.发送请求（request既能get也能post）</p>
<p>3.获取响应数据</p>
<p>4.持久化存储（响应数据）</p>
<p>环境配置</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231085243539.png" alt="image-20231231085243539"></p>
<h6 id="实战编码"><a href="#实战编码" class="headerlink" title="实战编码"></a>实战编码</h6><p>需求：搜狗搜首页的页面数据</p>
<p>源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231091438401.png" alt="image-20231231091438401"></p>
<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231091501983.png" alt="image-20231231091501983"></p>
<p>爬取的就是页面源码</p>
<p>我们可以打开去看一眼</p>
<p>源码在本地打开</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231091910930.png" alt="image-20231231091910930"></p>
<p> 继续实战</p>
<p>需求：爬取搜狗指定词条对应的搜索结果页面（简易网页采集器）指定一个关键字，搜索关键字的页面进行爬取</p>
<p>需求：破解百度翻译</p>
<p>需求：爬取豆瓣电影分来排行榜</p>
<p>需求：肯德基餐厅查询</p>
<p>需求：爬取国家药检局监督管理总局基于中华人民共和国化妆品生产许可相关数据</p>
<h6 id="1-第一个案例"><a href="#1-第一个案例" class="headerlink" title="1.第一个案例"></a>1.第一个案例</h6><p>后面无用的url可以删掉</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231092848333.png" alt="image-20231231092848333"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231092859480.png" alt="image-20231231092859480"></p>
<p>UA伪装</p>
<p>user-agent:请求载体，如果只用爬虫爬的话，门户网站的服务器会检测载体身份表示</p>
<p>如果是浏览器，说明是正常的请求，不会拒绝，如果不是基于浏览器，就会认为是不正常的的数据，服务器可能就会拒绝</p>
<p><img src="E:\blog\source_posts\爬虫初级.assets\image-20231231094400431.png" alt="image-20231231094400431"></p>
<p>为了我们爬取的成功一定要进行ua伪装</p>
<p>源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231094925510.png" alt="image-20231231094925510"></p>
<p>结果</p>
<p><img src="E:\blog\source_posts\爬虫初级.assets\image-20231231094946730.png" alt="image-20231231094946730"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231095001957.png" alt="image-20231231095001957"></p>
<p>成功爬取到了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231095239915.png" alt="image-20231231095239915"></p>
<p>2.百度翻译</p>
<p>我们这次的目标不是爬取页面的源码类的</p>
<p>而是想要翻译以后的结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231095542467.png" alt="image-20231231095542467"></p>
<p>爬到下面的词条(爬取局部的数据)</p>
<p> 我们在尝试的时候发现页面是局部刷新的应该利用的ajax</p>
<p>我们可以去抓取ajax的包</p>
<p>输入dog一个一个抓包发现</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100601556.png" alt="image-20231231100601556"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100620815.png" alt="image-20231231100620815"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100633377.png" alt="image-20231231100633377"></p>
<p>最后一个是我们想要捕获的数据包</p>
<p>就可以找到url<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100924908.png" alt="image-20231231100924908"></p>
<p>fanyi.baidu.com&#x2F;sug</p>
<p>响应头信息</p>
<p> <img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231101115687.png" alt="image-20231231101115687"></p>
<p>分析出</p>
<p>post请求（携带参数）</p>
<p>响应回来数据是json字符串</p>
<p>部分源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231103045458.png" alt="image-20231231103045458"></p>
<p>如果直接无脑保存会发现文件直接保存不了字典</p>
<p>所以我们这时就可以导入json模块</p>
<p>把字符串存在json的文本文件中</p>
<p>最后查看源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231103955374.png" alt="image-20231231103955374"></p>
<p>执行结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231104048403.png" alt="image-20231231104048403"></p>
<p>上面的dog的参数可以设置为一个动态的</p>
<p>总结：</p>
<p>1.注意观察包的数据（User-Agent，响应头 的content-type，请求的url地址，如果还是post的方法需要注意data部分的数据然后使用字典来写入，如果是get的方法要注意参数param 的这个部分）</p>
<p>2.字典直接写入不了文件，我们可以导入json，把字典写入json文件中</p>
<p>3.记得要伪造ua头</p>
<p>4.如果有页面部分刷新，类型看应该是ajax，我们应该筛选ajax的包，选择XHR即可</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231105035108.png" alt="image-20231231105035108"></p>
<h6 id="over"><a href="#over" class="headerlink" title="over"></a>over</h6><h6 id="3-爬取豆瓣电影的排行数据"><a href="#3-爬取豆瓣电影的排行数据" class="headerlink" title="3.爬取豆瓣电影的排行数据"></a>3.爬取豆瓣电影的排行数据</h6><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231105250254.png" alt="image-20231231105250254"></p>
<p>我们要爬取豆瓣电影的名称，导演，还有一些信息</p>
<p>这些人是局部信息，那是否用到你数据解析呢？</p>
<p>ok，不用数据解析也可以</p>
<p>我们发现当我们拖动滚轮的时候，每次拖动到底部，会自动加载，并且地址栏没变，局部刷新，并且看边上的滚轮会回到上面,我们怀疑和上面 的百度翻译使用的ajax</p>
<p>思路：</p>
<p>我们观察包</p>
<p>请求是get</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110036578.png" alt="image-20231231110036578"></p>
<p>返回的数据</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110104763.png" alt="image-20231231110104763"></p>
<p>get的几个参数</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110130366.png" alt="image-20231231110130366"></p>
<p>相应的json数据</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110257319.png" alt="image-20231231110257319"></p>
<p>源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231112721083.png" alt="image-20231231112721083"></p>
<p>写的没问题，不知道为什么报错</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231112824746.png" alt="image-20231231112824746"></p>
<p>总结</p>
<p>1.和上面的总结差不多，</p>
<p>over……</p>
<h6 id="4查询肯德基餐厅位置查询"><a href="#4查询肯德基餐厅位置查询" class="headerlink" title="4查询肯德基餐厅位置查询"></a>4查询肯德基餐厅位置查询</h6><h6 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h6><p>当我们查询的时候地址栏并没有改变</p>
<p>并且页面局部刷新</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113500648.png" alt="image-20231231113500648"></p>
<p>捕获数据包</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113601497.png" alt="image-20231231113601497"></p>
<p>post请求</p>
<p>post请求数据</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113712384.png" alt="image-20231231113712384"></p>
<p>我们可以分析可以改变可以改变keyword来获取不同的城市</p>
<p>但是这次不同 的是，响应回来的数据是文本了</p>
<p><img src="E:\blog\source_posts\爬虫初级.assets\image-20231231113952798.png" alt="image-20231231113952798"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231114127999.png" alt="image-20231231114127999"></p>
<p>但是我们可以用json的dump转成对象的形式</p>
<p>源码奉上自己编写的</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231115301944.png" alt="image-20231231115301944"></p>
<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231115323438.png" alt="image-20231231115323438"></p>
<p>再去json工具里面</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231115524933.png" alt="image-20231231115524933"></p>
<h6 id="6-国家药监总局"><a href="#6-国家药监总局" class="headerlink" title="6.国家药监总局"></a>6.国家药监总局</h6><p>没有找到网站</p>
<p>没有网站，先给出解析吧</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231134537539.png" alt="image-20231231134537539"></p>
<p>我们观察网站，尝试对首页进行爬取，或者看包，发现并没有企业的数据</p>
<p>怀疑shiajax的动态数据。随后我们抓取ajax的包发现里面还有id，并且进入一个企业中插查看和上部一样的操作，发现详情数据在ajax的相应包里面</p>
<p>解题思路：</p>
<p>1对首页的ajax的包进行爬取，爬取到id值，批量获取id值</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231134518861.png" alt="image-20231231134518861"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231135128661.png" alt="image-20231231135128661"></p>
<h6 id="request的模块的结束了"><a href="#request的模块的结束了" class="headerlink" title="request的模块的结束了"></a>request的模块的结束了</h6>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-03 19:10:54" itemprop="dateModified" datetime="2024-01-03T19:10:54+08:00">2024-01-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="验证码识别"><a href="#验证码识别" class="headerlink" title="验证码识别"></a>验证码识别</h1><p>验证码和爬虫的爱恨情仇？</p>
<p>反爬机制;验证码</p>
<p>如果爬取某些用户的一些信息</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102101127227.png" alt="image-20240102101127227"></p>
<p>需要录入验证码</p>
<p>需要进行处理</p>
<p>识别图片中的数据，模拟登录操作</p>
<p>识别验证码的操作</p>
<p>1人工肉眼识别‘：（不推荐）</p>
<p>2第三方自动识别：（推荐）</p>
<p>​	-云打码：好好好已经倒闭了</p>
<p>​	-超级鹰：		这个可以</p>
<p>实战;识别古诗文王登录页面的验证码。</p>
<p>使用打码平台的验证码的编码流程;</p>
<p>-加密和验证码进行本地下载</p>
<p>-调用平台的示例代码进行图片数据的识别</p>
<p>实战：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102105712755.png" alt="image-20240102105712755"></p>
<p>识别古诗文网登录页面的验证码</p>
<p>解题思路：</p>
<p>1.获取页面的源码和图片</p>
<p>2.导入识别验证码代码</p>
<p>3.为了方便封装识别验证码的函数</p>
<p>4.将剩余的验证码封装成一个类</p>
<p>代码详情：识别验证码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> codeclass <span class="keyword">import</span> Chaojiying_Client</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了简单封装识别验证码的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getCodeText</span>(<span class="params">img_path, Codetype</span>):</span><br><span class="line">    chaojiying = Chaojiying_Client(<span class="string">&#x27;chen1978&#x27;</span>, <span class="string">&#x27;wei3588559&#x27;</span>, <span class="string">&#x27;956857&#x27;</span>)  <span class="comment"># 用户中心&gt;&gt;软件ID 生成一个替换 96001</span></span><br><span class="line">    im = <span class="built_in">open</span>(img_path, <span class="string">&#x27;rb&#x27;</span>).read()</span><br><span class="line">    result = chaojiying.PostPic(im, Codetype)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx&#x27;</span></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">page_content = requests.get(url=url, headers=header).text</span><br><span class="line">tree = etree.HTML(page_content)</span><br><span class="line">img_url = <span class="string">&#x27;https://so.gushiwen.cn&#x27;</span> + tree.xpath(<span class="string">&#x27;//*[@id=&quot;imgCode&quot;]/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">img = requests.get(url=img_url, headers=header).content</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;验证码.jpg&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(img)  <span class="comment"># 将验证码图片保存在本地</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用打码平台</span></span><br><span class="line">code_txt = getCodeText(<span class="string">&#x27;验证码.jpg&#x27;</span>, <span class="number">1004</span>)</span><br><span class="line"><span class="built_in">print</span>(code_txt[<span class="string">&#x27;pic_str&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2codeclass的类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Chaojiying_Client</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, username, password, soft_id</span>):</span><br><span class="line">        self.username = username</span><br><span class="line">        password =  password.encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">        self.password = md5(password).hexdigest()</span><br><span class="line">        self.soft_id = soft_id</span><br><span class="line">        self.base_params = &#123;</span><br><span class="line">            <span class="string">&#x27;user&#x27;</span>: self.username,</span><br><span class="line">            <span class="string">&#x27;pass2&#x27;</span>: self.password,</span><br><span class="line">            <span class="string">&#x27;softid&#x27;</span>: self.soft_id,</span><br><span class="line">        &#125;</span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;Keep-Alive&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)&#x27;</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">PostPic</span>(<span class="params">self, im, codetype</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        im: 图片字节</span></span><br><span class="line"><span class="string">        codetype: 题目类型 参考 http://www.chaojiying.com/price.html</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;codetype&#x27;</span>: codetype,</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        files = &#123;<span class="string">&#x27;userfile&#x27;</span>: (<span class="string">&#x27;ccc.jpg&#x27;</span>, im)&#125;</span><br><span class="line">        r = requests.post(<span class="string">&#x27;http://upload.chaojiying.net/Upload/Processing.php&#x27;</span>, data=params, files=files, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">PostPic_base64</span>(<span class="params">self, base64_str, codetype</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        im: 图片字节</span></span><br><span class="line"><span class="string">        codetype: 题目类型 参考 http://www.chaojiying.com/price.html</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;codetype&#x27;</span>: codetype,</span><br><span class="line">            <span class="string">&#x27;file_base64&#x27;</span>:base64_str</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        r = requests.post(<span class="string">&#x27;http://upload.chaojiying.net/Upload/Processing.php&#x27;</span>, data=params, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ReportError</span>(<span class="params">self, im_id</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        im_id:报错题目的图片ID</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: im_id,</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        r = requests.post(<span class="string">&#x27;http://upload.chaojiying.net/Upload/ReportError.php&#x27;</span>, data=params, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br></pre></td></tr></table></figure>

<p>将超级鹰给出的代码分别封装就可以</p>
<p>我们也可以通过参数传递路径和类型</p>
<p>例如：传入img_path和Codetype</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getCodeText</span>(<span class="params">img_path, Codetype</span>):</span><br><span class="line">    chaojiying = Chaojiying_Client(<span class="string">&#x27;chen1978&#x27;</span>, <span class="string">&#x27;wei3588559&#x27;</span>, <span class="string">&#x27;956857&#x27;</span>)  <span class="comment"># 用户中心&gt;&gt;软件ID 生成一个替换 96001</span></span><br><span class="line">    im = <span class="built_in">open</span>(img_path, <span class="string">&#x27;rb&#x27;</span>).read()</span><br><span class="line">    result = chaojiying.PostPic(im, Codetype)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<p>识别的验证码可能会有一些误差</p>
<p>实战：模拟登录</p>
<p>​			-爬取基于某些用户的个人信息</p>
<p>​			-登录成功后才能进行数据分析</p>
<p>需求：</p>
<p>对人人网进行模拟登录</p>
<p>没有网站的了，讲一下思路吧；</p>
<p>1.开始登录页面需要验证码和账号密码</p>
<p>2.正常登录后，查看数据包，有个login的包，已更改就是登录的包</p>
<p>3.是个post的请求里面的data携带账号密码和验证码</p>
<p>4.我们就可以先发起个get请求到登录页面，然后获取账号密码和验证码</p>
<p>5.然后发起post请求里面的参数验证修改</p>
<p>6.然后对页面的数据进行持久化存储</p>
<p>7.注意有可能存储的不是页面源码我们可以在判断一下看以下页面的响应码</p>
<p>这么写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102121732817.png" alt="image-20240102121732817"></p>
<h4 id="模拟cookie登录"><a href="#模拟cookie登录" class="headerlink" title="模拟cookie登录"></a>模拟cookie登录</h4><p>爬取当前用户相关信息</p>
<p>爬取个人主页对应的页面数据</p>
<p>基于cookie的操作</p>
<p>http，https都是无状态协议</p>
<p>如果我们在紧接上部登录以后在访问简介获取简介的源码数据的话</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102130154957.png" alt="image-20240102130154957"></p>
<p>这段代码可能返回的源码数据可能不是简介的源码数据</p>
<p>可能是登录的源码的数据 </p>
<p>因为http是无状态的所以不会记录上一部分登录成功的部分</p>
<p>导致第二次登录 的请求，服务器并不知道是否处于登录状态</p>
<p>cookie记录客户端的状态</p>
<p>浏览器的包</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102130650459.png" alt="image-20240102130650459"></p>
<p>所以我们也可以伪造cookie</p>
<p>1手动cookie配置(通用行不强)</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102130825556.png" alt="image-20240102130825556"></p>
<p>2自动处理</p>
<p>cookie的来源？</p>
<p>在我们的登录的时候的响应包</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102131056840.png" alt="image-20240102131056840"></p>
<p>服务器会给我们创建cookie</p>
<p>用到session会话对象：</p>
<p>​	-作用：可以请求的发送和requests一样</p>
<p>​	-如果请求的过程中产生了cookie，则该cookie会被自动储存在sessin中</p>
<p>步骤</p>
<p>1.使用session对像金总模拟post请求的发送(cookie会被自动储存在session中)</p>
<p>2.session对象对个人主页对应get亲贵发送（携带了cookie）</p>
<p>创建session对象:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">session=requests.Session()</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102131919688.png" alt="image-20240102131919688"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102131947670.png" alt="image-20240102131947670"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102132014868.png" alt="image-20240102132014868"></p>
<h6 id="使用代理ip的相关操作"><a href="#使用代理ip的相关操作" class="headerlink" title="使用代理ip的相关操作"></a>使用代理ip的相关操作</h6><p>-你的ip访问次数过多</p>
<p>-访问超过了单位时间的次数</p>
<p>用来破解封ip的反爬机制</p>
<p>什么代理:</p>
<p>​		-代理服务器，请求先到代理服务器再去服务器，ip就是代理服务器的</p>
<p>代理的作用：</p>
<p>​		-突破自身ip访问的限制</p>
<p>​		-可以隐藏自身ip免受攻击</p>
<p>代理网站：</p>
<p>​		-快代理</p>
<p>​		-西祠代理</p>
<p>​		-<a target="_blank" rel="noopener" href="http://www.goubanjia.com/">www.goubanjia.com</a></p>
<p>代理的操作</p>
<p>代理ip类型</p>
<p>1.http：应用到http协议对应的url</p>
<p>2.https：应用到https协议对应的url</p>
<p>如果我们要访问</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">page_text=requests.get(url=url,headers=header).text</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;ip.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(page_text)</span><br></pre></td></tr></table></figure>

<p>就需要https的代理</p>
<p>找到一个免费代理的网站（<a target="_blank" rel="noopener" href="http://www.ip3366.net/">云代理 - 高品质http代理ip供应平台_免费代理IP (ip3366.net)</a>）</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102135610142.png" alt="image-20240102135610142"></p>
<p>如何实现？</p>
<p>在get请求中添加参数proxies的参数</p>
<p>源码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">proxy=&#123;</span><br><span class="line">    <span class="string">&#x27;HTTPS&#x27;</span>:<span class="string">&#x27;117.71.149.139&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">page_text=requests.get(url=url,headers=header,proxies=proxy).text</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;ip.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(page_text)</span><br></pre></td></tr></table></figure>

<p>这样就可以设置ip</p>
<p>应用了 代理服务器的ip</p>
<p>还有匿名读</p>
<p>1.透明：服务器知道使用代理，也知道请求对应的可真实 的ip</p>
<p>2.匿名：知道使用代理，不知道真实的ip</p>
<p>3.高匿：不知道使用了代理，也不知道真实的ip</p>
<h3 id="高性能异步爬虫"><a href="#高性能异步爬虫" class="headerlink" title="高性能异步爬虫"></a>高性能异步爬虫</h3><p>目的：</p>
<p>在爬虫中使用异步实现高性能的数据爬取操作。</p>
<p>单线程下使用串行的方式进行数据的发送</p>
<p>例子：如下面的代码一共多个人url，get的请求只会依次的的发送请求，导致了get请求是一个堵塞的方法，如果我们有成百上千的方法的话，那么可能就会执行的很慢就造成了堵塞</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102142502764.png" alt="image-20240102142502764"></p>
<p> 爬取数据的效率比较低</p>
<p>就要使用异步了</p>
<p>异步爬虫的方式：</p>
<p>​			-多进程,多线程（不建议）:</p>
<p>​                    好处：为阻塞的操作单独安排的进程，阻塞操作可以异步操作</p>
<p>​					弊端：无法无限制的开启多线程或者进程如果很多的话会占用cpu的资源</p>
<p>​		-进程池.线程池（适当的使用）：</p>
<p>​				好处：我们可以降低系统对线程或者线程创建和销毁的一个频率从而降低西系统开销</p>
<p>​				弊端：池中线程或者进程的数量是有限的</p>
<p>模拟单线程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_page</span>(<span class="params"><span class="built_in">str</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在下载：&quot;</span>,<span class="built_in">str</span>)</span><br><span class="line">    time.sleep(<span class="number">2</span>)<span class="comment">#模拟get的阻塞</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;下载成功：&quot;</span>,<span class="built_in">str</span>)</span><br><span class="line">name_list=[<span class="string">&#x27;hututu&#x27;</span>,<span class="string">&#x27;wangchangxhebn&#x27;</span>,<span class="string">&#x27;libai&#x27;</span>,<span class="string">&#x27;zhangfeui0&#x27;</span>]</span><br><span class="line"><span class="comment">#模拟多个url</span></span><br><span class="line">start_time=time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_list)):</span><br><span class="line">    get_page(name_list[name])</span><br><span class="line">end_time=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;%d&quot;</span>%(end_time-start_time))</span><br></pre></td></tr></table></figure>

<p>耗时</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102152027299.png" alt="image-20240102152027299"></p>
<p>基于线程池的方式：</p>
<p>多线程 的操作流程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool<span class="comment">#使用线程池的方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_page</span>(<span class="params"><span class="built_in">str</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在下载：&quot;</span>,<span class="built_in">str</span>)</span><br><span class="line">    time.sleep(<span class="number">2</span>)<span class="comment">#模拟get的阻塞</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;下载成功：&quot;</span>,<span class="built_in">str</span>)</span><br><span class="line">name_list=[<span class="string">&#x27;hututu&#x27;</span>,<span class="string">&#x27;wangchangxhebn&#x27;</span>,<span class="string">&#x27;libai&#x27;</span>,<span class="string">&#x27;zhangfeui0&#x27;</span>]</span><br><span class="line"><span class="comment">#模拟多个url</span></span><br><span class="line">start_time=time.time()</span><br><span class="line"><span class="comment">#实例化pool对象</span></span><br><span class="line">pool=Pool()</span><br><span class="line">pool.<span class="built_in">map</span>(get_page,name_list)<span class="comment">#其中一个参数是堵塞的操作，第二个应用的值，应为没有返回值所以不用接收，将列表中每一个值传入</span></span><br><span class="line">end_time=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;%dsecond&quot;</span>%(end_time-start_time))</span><br></pre></td></tr></table></figure>

<p>返回的时间</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240102153442144.png" alt="image-20240102153442144"></p>
<p>实战：</p>
<p>爬取梨视频的视频数据</p>
<p>原则:爬取堵塞耗时的操作</p>
<p><a target="_blank" rel="noopener" href="https://www.pearvideo.com/category_1">人物热点短视频_-梨视频官网-Pear Video-梨网站</a></p>
<p>获得视频的名称和视频</p>
<p>流程：</p>
<p>1.获得页面的全部数据，视频名称和视频详情页的url</p>
<p>2.进入视频详情页进行获取视频的数据</p>
<p>这个网站又增加了反爬策略</p>
<p>验证referer 而且数据也是通过ajax加载出来的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span></span><br><span class="line">                  <span class="string">&#x27;Chrome/88.0.4324.182 Safari/537.36&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.pearvideo.com/video_1790562&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># Referer参数是视频ID，必须加上不然请求不到数据，估计是梨视频的反爬机制之一</span></span><br><span class="line">url = <span class="string">&#x27;https://www.pearvideo.com/videoStatus.jsp?contId=1790562&amp;mrd=0.019795902061482185&#x27;</span></span><br><span class="line"><span class="comment"># contId为视频ID</span></span><br><span class="line"></span><br><span class="line">res = requests.get(url=url, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(res.text)</span><br></pre></td></tr></table></figure>

<p>这样可以获取视频的链接</p>
<p>然后把字典里的链接提取出来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span></span><br><span class="line">                  <span class="string">&#x27;Chrome/88.0.4324.182 Safari/537.36&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.pearvideo.com/video_1790562&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># Referer参数是视频ID，必须加上不然请求不到数据，估计是梨视频的反爬机制之一</span></span><br><span class="line">url = <span class="string">&#x27;https://www.pearvideo.com/videoStatus.jsp?contId=1790562&amp;mrd=0.019795902061482185&#x27;</span></span><br><span class="line"><span class="comment"># contId为视频ID</span></span><br><span class="line"></span><br><span class="line">res = requests.get(url=url, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(res.text)</span><br><span class="line">json_text=json.loads(res.text)</span><br><span class="line"><span class="built_in">print</span>(json_text[<span class="string">&#x27;videoInfo&#x27;</span>][<span class="string">&#x27;videos&#x27;</span>][<span class="string">&#x27;srcUrl&#x27;</span>])<span class="comment">#可以使用json模块将该字符串解析为 Python 对象，然后获取其中的srcUrl属性</span></span><br><span class="line"><span class="comment"># print(res.text[2][2][4])如果不插入json的话就要这么写</span></span><br></pre></td></tr></table></figure>

<h2 id="单线程-异步协程（推荐）："><a href="#单线程-异步协程（推荐）：" class="headerlink" title="单线程+异步协程（推荐）："></a>单线程+异步协程（推荐）：</h2><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103104143772.png" alt="image-20240103104143772"></p>
<p>协程方法不会在调用的时候被执行，需要把协程对象放在书简循环</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span>  <span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在请求的url是 &quot;</span>,url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求成功&quot;</span>,url)</span><br><span class="line">request(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>直接执行会报错</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103104812732.png" alt="image-20240103104812732"></p>
<p>需要创建事件循环，将协程对象添加到事件循环中去</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span>  <span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在请求的url是 &quot;</span>,url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求成功&quot;</span>,url)</span><br><span class="line">c=request(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()#创建循环对象</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(c)#写成对象注册到loop中去</span></span><br><span class="line">asyncio.run(c)</span><br></pre></td></tr></table></figure>

<h6 id="Task的使用"><a href="#Task的使用" class="headerlink" title="Task的使用"></a>Task的使用</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span>  <span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在请求的url是 &quot;</span>,url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求成功&quot;</span>,url)</span><br><span class="line">c=request(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()#创建循环对象</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(c)#写成对象注册到loop中去</span></span><br><span class="line"><span class="comment"># asyncio.run(c)</span></span><br><span class="line"><span class="comment">#task的使用</span></span><br><span class="line">loop=asyncio.get_event_loop()</span><br><span class="line">task=loop.create_task(c)<span class="comment">#基于loop创建一个task对象</span></span><br><span class="line"><span class="built_in">print</span>(task)<span class="comment">#task可以显示人物的状态</span></span><br><span class="line">loop.run_until_complete(task)<span class="comment">#将任务注册到事件循环中</span></span><br><span class="line"><span class="built_in">print</span>(task)<span class="comment">#结束再来看任务的状态</span></span><br></pre></td></tr></table></figure>

<p>执行的结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103105742941.png" alt="image-20240103105742941"></p>
<p>pending：任务还没有被执行</p>
<p>finished：任务执行执行完毕</p>
<h6 id="future对象"><a href="#future对象" class="headerlink" title="future对象"></a>future对象</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span>  <span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在请求的url是 &quot;</span>,url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求成功&quot;</span>,url)</span><br><span class="line">c=request(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()#创建循环对象</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(c)#写成对象注册到loop中去</span></span><br><span class="line"><span class="comment"># asyncio.run(c)</span></span><br><span class="line"><span class="comment">#task的使用</span></span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()</span></span><br><span class="line"><span class="comment"># task=loop.create_task(c)#基于loop创建一个task对象</span></span><br><span class="line"><span class="comment"># print(task)#task可以显示人物的状态</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(task)#将任务注册到事件循环中</span></span><br><span class="line"><span class="comment"># print(task)#结束再来看任务的状态</span></span><br><span class="line"><span class="comment">#future的使用</span></span><br><span class="line">loop=asyncio.get_event_loop()</span><br><span class="line">future=asyncio.ensure_future(c)<span class="comment">#与task的不同，这个不是基loop</span></span><br><span class="line"><span class="built_in">print</span>(future)</span><br><span class="line">loop.run_until_complete(future)</span><br><span class="line"><span class="built_in">print</span>(future)</span><br></pre></td></tr></table></figure>

<p>绑定回调</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">async</span>  <span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在请求的url是 &quot;</span>,url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求成功&quot;</span>,url)</span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line">c=request(<span class="string">&#x27;www.baidu.com&#x27;</span>)</span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()#创建循环对象</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(c)#写成对象注册到loop中去</span></span><br><span class="line"><span class="comment"># asyncio.run(c)</span></span><br><span class="line"><span class="comment">#task的使用</span></span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()</span></span><br><span class="line"><span class="comment"># task=loop.create_task(c)#基于loop创建一个task对象</span></span><br><span class="line"><span class="comment"># print(task)#task可以显示人物的状态</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(task)#将任务注册到事件循环中</span></span><br><span class="line"><span class="comment"># print(task)#结束再来看任务的状态</span></span><br><span class="line"><span class="comment">#future的使用</span></span><br><span class="line"><span class="comment"># loop=asyncio.get_event_loop()</span></span><br><span class="line"><span class="comment"># future=asyncio.ensure_future(c)#与task的不同，这个不是基loop</span></span><br><span class="line"><span class="comment"># print(future)</span></span><br><span class="line"><span class="comment"># loop.run_until_complete(future)</span></span><br><span class="line"><span class="comment"># print(future)</span></span><br><span class="line"><span class="comment">#绑定回调函数、</span></span><br><span class="line"><span class="comment">#先定义一个回调函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_back</span>(<span class="params">task</span>):</span><br><span class="line">    <span class="built_in">print</span>(task.result())</span><br><span class="line">    <span class="comment">#result方法返回的是那个的返回值</span></span><br><span class="line">loop=asyncio.get_event_loop()</span><br><span class="line">task=asyncio.ensure_future(c)</span><br><span class="line"><span class="comment">#将回调函数绑定到任务对象当中去</span></span><br><span class="line">task.add_done_callback(call_back)<span class="comment">#这里可以不用使用参数，会将创建的task的返回值当作参数</span></span><br><span class="line">loop.run_until_complete(task)</span><br></pre></td></tr></table></figure>

<h6 id="多任务协程"><a href="#多任务协程" class="headerlink" title="多任务协程"></a>多任务协程</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">requests</span>(<span class="params">url</span>):</span><br><span class="line">     <span class="built_in">print</span>(<span class="string">&quot;正在下载&quot;</span>,url)</span><br><span class="line">     time.sleep(<span class="number">2</span>)<span class="comment">#模拟下载操作</span></span><br><span class="line">     <span class="built_in">print</span>(<span class="string">&quot;下载完毕&quot;</span>,url)</span><br><span class="line">start=time.time()</span><br><span class="line">urls=[</span><br><span class="line">    <span class="number">11111111</span>,</span><br><span class="line">    <span class="number">2222222</span>,</span><br><span class="line">    <span class="number">22222223</span></span><br><span class="line">]</span><br><span class="line"><span class="comment">#存放多个任务对象</span></span><br><span class="line">status=[]</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    c=requests(url)</span><br><span class="line">    loop=asyncio.get_event_loop()</span><br><span class="line">    Future= asyncio.ensure_future(c)</span><br><span class="line">    status.append(Future)<span class="comment">#把任务放在任务列表</span></span><br><span class="line">    loop.run_until_complete(asyncio.<span class="keyword">await</span>(status))</span><br><span class="line">    <span class="built_in">print</span>(time.time()-start)</span><br></pre></td></tr></table></figure>

<p>执行后发现还是同步 的</p>
<p>原因是</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103112749814.png" alt="image-20240103112749814"></p>
<p>time.time(2)是同步操作需要导入asyncio里面的</p>
<p>修改完</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103112928100.png" alt="image-20240103112928100"></p>
<p>现在就实现异步了</p>
<h6 id="aiohttp模块"><a href="#aiohttp模块" class="headerlink" title="aiohttp模块"></a>aiohttp模块</h6><p>基于异步请求的模块</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103190918308.png" alt="image-20240103190918308"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103191008405.png" alt="image-20240103191008405"></p>
<p>已经放弃的了</p>
<p>真的很难</p>
<p>n</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E7%88%AC%E8%99%AB%E9%80%86%E5%90%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E7%88%AC%E8%99%AB%E9%80%86%E5%90%91/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-11 10:54:00" itemprop="dateModified" datetime="2024-01-11T10:54:00+08:00">2024-01-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="爬虫逆向"><a href="#爬虫逆向" class="headerlink" title="爬虫逆向"></a>爬虫逆向</h1><p>图灵</p>
<h2 id="逆向算法"><a href="#逆向算法" class="headerlink" title="逆向算法"></a>逆向算法<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240111085741567.png" alt="image-20240111085741567"></h2><p>动态数据的请求</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240111091621065.png" alt="image-20240111091621065"></p>
<pre><code> 第一次请求只会获取到资源文件和一些其他的东西不会 获取到数据
</code></pre>
<p>第二次返回的 数据是已经加密过的数据</p>
<p>然后通过第一次返回的密钥和一些js文件进行解密</p>
<p>数据加密</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240111091859298.png" alt="image-20240111091859298"></p>
<p>先搜索解密</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240111092001323.png" alt="image-20240111092001323"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240111092014188.png" alt="image-20240111092014188"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240111092225625.png" alt="image-20240111092225625"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E7%88%AC%E8%99%AB/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-01-29 16:15:30 / 修改时间：16:16:53" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="爬虫初级"><a href="#爬虫初级" class="headerlink" title="爬虫初级"></a>爬虫初级</h1><h4 id="作者：饭桶晨"><a href="#作者：饭桶晨" class="headerlink" title="作者：饭桶晨"></a>作者：饭桶晨</h4><h4 id="QQ：3445883193"><a href="#QQ：3445883193" class="headerlink" title="QQ：3445883193"></a>QQ：3445883193</h4><h4 id="csdn：翻斗花园突破手胡图图122"><a href="#csdn：翻斗花园突破手胡图图122" class="headerlink" title="csdn：翻斗花园突破手胡图图122"></a>csdn：翻斗花园突破手胡图图122</h4><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230200215985.png" alt="image-20231230200215985"></p>
<h6 id="什么是爬虫？"><a href="#什么是爬虫？" class="headerlink" title="什么是爬虫？"></a>什么是爬虫？</h6><p>通过编写程序，模拟浏览器上网，然后让其去互联网抓取数据的过程。</p>
<h6 id="爬虫的价值："><a href="#爬虫的价值：" class="headerlink" title="爬虫的价值："></a>爬虫的价值：</h6><p>当然是为了提升自己的物质生活或者精神生活。现在经常听到<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%A4%A7%E6%95%B0%E6%8D%AE&spm=1001.2101.3001.7020">大数据</a>时代，哎，数据就是 Money 哦，很少存在数据共享的，这个时候，那我们就得自己靠本事找数据啦。搜寻数据这个过程其实并不想象中的难，每个领域的人都可以利用该技术得到自己想要的</p>
<h6 id="爬虫的合法性？"><a href="#爬虫的合法性？" class="headerlink" title="爬虫的合法性？"></a>爬虫的合法性？</h6><p>1.具有违法风险</p>
<p>2.在法律中是不被禁止</p>
<p>3.窃取后台数据就会违法</p>
<p>4.善意爬虫</p>
<p>5.恶意爬虫：干扰了被访问网站的正常运行，抓去了收到法律保护的特定类型的数据和信息</p>
<h6 id="如何避免？"><a href="#如何避免？" class="headerlink" title="如何避免？"></a>如何避免？</h6><p>1.时常优化程序</p>
<p>2在使用，传播爬到的数据，审查内容</p>
<p>3商业机密等敏感需要及时停止爬取</p>
<h6 id="爬虫的分类"><a href="#爬虫的分类" class="headerlink" title="爬虫的分类"></a>爬虫的分类</h6><p>1.通用爬虫：抓取系统重要组成部分,抓取的是整张页面</p>
<p>2.聚集爬虫：指定的局部内容</p>
<p>3.增量式爬虫：检测网站数据更新的情况。只会抓取更新最新的数据</p>
<h6 id="反爬机制"><a href="#反爬机制" class="headerlink" title="反爬机制"></a>反爬机制</h6><p> 门户网站，可以通过指定相应的技术和策略</p>
<h6 id="反反爬机制"><a href="#反反爬机制" class="headerlink" title="反反爬机制"></a>反反爬机制</h6><p>破解门户网站的反爬机制，从而获取门户网站的信息</p>
<h6 id="robots-txt协议（反反爬机制，君子协议）"><a href="#robots-txt协议（反反爬机制，君子协议）" class="headerlink" title="robots.txt协议（反反爬机制，君子协议）"></a>robots.txt协议（反反爬机制，君子协议）</h6><p>规定那些可以被爬，那些不可以被爬</p>
<p>可以遵从，可以不遵从；</p>
<p>列如</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230202651322.png" alt="image-20231230202651322"></p>
<p>不遵从可能会有法律问题</p>
<h4 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h4><p>概念：服务器和客户端进行数据交互的一种方式。（就比如威虎山里面的黑话）</p>
<h6 id="常用请求头信息"><a href="#常用请求头信息" class="headerlink" title="常用请求头信息"></a>常用请求头信息</h6><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230203119605.png" alt="image-20231230203119605"></p>
<p>这就是请求头（不详解了）</p>
<p>connect是请求完毕以后是保持连接还是断开</p>
<h6 id="响应头信息"><a href="#响应头信息" class="headerlink" title="响应头信息"></a>响应头信息</h6><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230203344976.png" alt="image-20231230203344976"></p>
<p>content-type：服务器返回客户端的数据类型</p>
<h6 id="https协议"><a href="#https协议" class="headerlink" title="https协议"></a>https协议</h6><p>传续的数据进行加密</p>
<h6 id="加密方式"><a href="#加密方式" class="headerlink" title="加密方式"></a>加密方式</h6><p>1：对称加密</p>
<p>加密的钥匙和密文都传过去</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231230203648592.png" alt="image-20231230203648592"></p>
<p>2：非对称加密</p>
<p>有私钥和公钥，无法保证客户端拿到的公钥是服务器发来的，有可能人篡改</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231083933191.png" alt="image-20231231083933191"></p>
<p>3：证书密钥加密</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231084340066.png" alt="image-20231231084340066"></p>
<p>保证了客户端的拿到的是服务器端发来的</p>
<h2 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h2><h6 id="网络请求的模块"><a href="#网络请求的模块" class="headerlink" title="网络请求的模块"></a>网络请求的模块</h6><p>1.urllib模块</p>
<p>2.requests模块</p>
<p>主要第二个</p>
<p>概念：基于python原生的一款网络请求的模块</p>
<p>作用：模拟浏览器发送请求</p>
<p>如何使用？</p>
<p>需要遵从浏览器发送请求的方式；（编码流程）</p>
<p>1.指定url</p>
<p>2.发送请求（request既能get也能post）</p>
<p>3.获取响应数据</p>
<p>4.持久化存储（响应数据）</p>
<p>环境配置</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231085243539.png" alt="image-20231231085243539"></p>
<h6 id="实战编码"><a href="#实战编码" class="headerlink" title="实战编码"></a>实战编码</h6><p>需求：搜狗搜首页的页面数据</p>
<p>源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231091438401.png" alt="image-20231231091438401"></p>
<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231091501983.png" alt="image-20231231091501983"></p>
<p>爬取的就是页面源码</p>
<p>我们可以打开去看一眼</p>
<p>源码在本地打开</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231091910930.png" alt="image-20231231091910930"></p>
<p> 继续实战</p>
<p>需求：爬取搜狗指定词条对应的搜索结果页面（简易网页采集器）指定一个关键字，搜索关键字的页面进行爬取</p>
<p>需求：破解百度翻译</p>
<p>需求：爬取豆瓣电影分来排行榜</p>
<p>需求：肯德基餐厅查询</p>
<p>需求：爬取国家药检局监督管理总局基于中华人民共和国化妆品生产许可相关数据</p>
<h6 id="1-第一个案例"><a href="#1-第一个案例" class="headerlink" title="1.第一个案例"></a>1.第一个案例</h6><p>后面无用的url可以删掉</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231092848333.png" alt="image-20231231092848333"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231092859480.png" alt="image-20231231092859480"></p>
<p>UA伪装</p>
<p>user-agent:请求载体，如果只用爬虫爬的话，门户网站的服务器会检测载体身份表示</p>
<p>如果是浏览器，说明是正常的请求，不会拒绝，如果不是基于浏览器，就会认为是不正常的的数据，服务器可能就会拒绝</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231094400431.png" alt="image-20231231094400431"></p>
<p>为了我们爬取的成功一定要进行ua伪装</p>
<p>源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231094925510.png" alt="image-20231231094925510"></p>
<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231094946730.png" alt="image-20231231094946730"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231095001957.png" alt="image-20231231095001957"></p>
<p>成功爬取到了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231095239915.png" alt="image-20231231095239915"></p>
<p>2.百度翻译</p>
<p>我们这次的目标不是爬取页面的源码类的</p>
<p>而是想要翻译以后的结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231095542467.png" alt="image-20231231095542467"></p>
<p>爬到下面的词条(爬取局部的数据)</p>
<p> 我们在尝试的时候发现页面是局部刷新的应该利用的ajax</p>
<p>我们可以去抓取ajax的包</p>
<p>输入dog一个一个抓包发现</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100601556.png" alt="image-20231231100601556"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100620815.png" alt="image-20231231100620815"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100633377.png" alt="image-20231231100633377"></p>
<p>最后一个是我们想要捕获的数据包</p>
<p>就可以找到url<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231100924908.png" alt="image-20231231100924908"></p>
<p>fanyi.baidu.com&#x2F;sug</p>
<p>响应头信息</p>
<p> <img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231101115687.png" alt="image-20231231101115687"></p>
<p>分析出</p>
<p>post请求（携带参数）</p>
<p>响应回来数据是json字符串</p>
<p>部分源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231103045458.png" alt="image-20231231103045458"></p>
<p>如果直接无脑保存会发现文件直接保存不了字典</p>
<p>所以我们这时就可以导入json模块</p>
<p>把字符串存在json的文本文件中</p>
<p>最后查看源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231103955374.png" alt="image-20231231103955374"></p>
<p>执行结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231104048403.png" alt="image-20231231104048403"></p>
<p>上面的dog的参数可以设置为一个动态的</p>
<p>总结：</p>
<p>1.注意观察包的数据（User-Agent，响应头 的content-type，请求的url地址，如果还是post的方法需要注意data部分的数据然后使用字典来写入，如果是get的方法要注意参数param 的这个部分）</p>
<p>2.字典直接写入不了文件，我们可以导入json，把字典写入json文件中</p>
<p>3.记得要伪造ua头</p>
<p>4.如果有页面部分刷新，类型看应该是ajax，我们应该筛选ajax的包，选择XHR即可</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231105035108.png" alt="image-20231231105035108"></p>
<h6 id="over"><a href="#over" class="headerlink" title="over"></a>over</h6><h6 id="3-爬取豆瓣电影的排行数据"><a href="#3-爬取豆瓣电影的排行数据" class="headerlink" title="3.爬取豆瓣电影的排行数据"></a>3.爬取豆瓣电影的排行数据</h6><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231105250254.png" alt="image-20231231105250254"></p>
<p>我们要爬取豆瓣电影的名称，导演，还有一些信息</p>
<p>这些人是局部信息，那是否用到你数据解析呢？</p>
<p>ok，不用数据解析也可以</p>
<p>我们发现当我们拖动滚轮的时候，每次拖动到底部，会自动加载，并且地址栏没变，局部刷新，并且看边上的滚轮会回到上面,我们怀疑和上面 的百度翻译使用的ajax</p>
<p>思路：</p>
<p>我们观察包</p>
<p>请求是get</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110036578.png" alt="image-20231231110036578"></p>
<p>返回的数据</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110104763.png" alt="image-20231231110104763"></p>
<p>get的几个参数</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110130366.png" alt="image-20231231110130366"></p>
<p>相应的json数据</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231110257319.png" alt="image-20231231110257319"></p>
<p>源码</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231112721083.png" alt="image-20231231112721083"></p>
<p>写的没问题，不知道为什么报错</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231112824746.png" alt="image-20231231112824746"></p>
<p>总结</p>
<p>1.和上面的总结差不多，</p>
<p>over……</p>
<h6 id="4查询肯德基餐厅位置查询"><a href="#4查询肯德基餐厅位置查询" class="headerlink" title="4查询肯德基餐厅位置查询"></a>4查询肯德基餐厅位置查询</h6><h6 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h6><p>当我们查询的时候地址栏并没有改变</p>
<p>并且页面局部刷新</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113500648.png" alt="image-20231231113500648"></p>
<p>捕获数据包</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113601497.png" alt="image-20231231113601497"></p>
<p>post请求</p>
<p>post请求数据</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113712384.png" alt="image-20231231113712384"></p>
<p>我们可以分析可以改变可以改变keyword来获取不同的城市</p>
<p>但是这次不同 的是，响应回来的数据是文本了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231113952798.png" alt="image-20231231113952798"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231114127999.png" alt="image-20231231114127999"></p>
<p>但是我们可以用json的dump转成对象的形式</p>
<p>源码奉上自己编写的</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231115301944.png" alt="image-20231231115301944"></p>
<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231115323438.png" alt="image-20231231115323438"></p>
<p>再去json工具里面</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231115524933.png" alt="image-20231231115524933"></p>
<h6 id="6-国家药监总局"><a href="#6-国家药监总局" class="headerlink" title="6.国家药监总局"></a>6.国家药监总局</h6><p>没有找到网站</p>
<p>没有网站，先给出解析吧</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231134537539.png" alt="image-20231231134537539"></p>
<p>我们观察网站，尝试对首页进行爬取，或者看包，发现并没有企业的数据</p>
<p>怀疑shiajax的动态数据。随后我们抓取ajax的包发现里面还有id，并且进入一个企业中插查看和上部一样的操作，发现详情数据在ajax的相应包里面</p>
<p>解题思路：</p>
<p>1对首页的ajax的包进行爬取，爬取到id值，批量获取id值</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231134518861.png" alt="image-20231231134518861"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231135128661.png" alt="image-20231231135128661"></p>
<h6 id="request的模块的结束了"><a href="#request的模块的结束了" class="headerlink" title="request的模块的结束了"></a>request的模块的结束了</h6>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E7%88%AC%E8%99%AB%E5%8D%87%E7%BA%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E7%88%AC%E8%99%AB%E5%8D%87%E7%BA%A7/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-06 18:09:12" itemprop="dateModified" datetime="2024-01-06T18:09:12+08:00">2024-01-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="爬虫升级"><a href="#爬虫升级" class="headerlink" title="爬虫升级"></a>爬虫升级</h1><p>开端：</p>
<p>如何拿到动态加载的数据呢？</p>
<p>在之前的药检局的案例中</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103191559597.png" alt="image-20240103191559597"></p>
<p>可以发现网站应的包里的响应并没有我们要找的</p>
<p>然后我们可以全局搜索查看在其他的包中</p>
<p>然后在对应请求获取数据</p>
<p>就引入了 slenium的模块</p>
<h6 id="selenium模块的基本使用"><a href="#selenium模块的基本使用" class="headerlink" title="selenium模块的基本使用"></a>selenium模块的基本使用</h6><p>1.作用便捷的获取网站中动态加载的数据</p>
<p>2.便捷实现模拟登录</p>
<p>什么是selenium？</p>
<p>基于浏览器自动化的 一个模块</p>
<p>完成浏览器自动化的动作，编写代码不需要你动手</p>
<p>selenium的使用流程？</p>
<p>1.环境的安装</p>
<p>pip install selenium</p>
<ol start="2">
<li></li>
</ol>
<p>下载浏览器的驱动程序</p>
<p>下载成功后放在当前目录下</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103193518790.png" alt="image-20240103193518790"></p>
<ol start="3">
<li></li>
</ol>
<p>实例化一个浏览器对象：</p>
<ol start="4">
<li></li>
</ol>
<p>编写基于浏览器	自动化的操作代码</p>
<p>老师教的代码已经过时执行后会报错</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.service <span class="keyword">import</span> Service</span><br><span class="line"></span><br><span class="line">service = Service(<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line">driver = webdriver.Edge(service=service)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开xxx网站</span></span><br><span class="line">driver.get(<span class="string">&#x27;https://baidu.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这是改进后的</p>
<p>目标实现：1.便捷实现动态加载的数据</p>
<p>代码需要把前面的修改以下可修改成我上的格式</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103200720429.png" alt="image-20240103200720429"></p>
<p>这样的操作就可以让我们获取当前页面动态加载的数据</p>
<p>之前直接去访问是获取不到的</p>
<p>拿到了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103200828771.png" alt="image-20240103200828771"></p>
<p>因为网页找不到了我就不演示了</p>
<p>2.其他操作的实现</p>
<p>打开淘宝，然后进行搜索还有滚轮向下滚动</p>
<p>打开淘宝定位搜索框</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103201919721.png" alt="image-20240103201919721"></p>
<p>老师的操作</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103202730120.png" alt="image-20240103202730120"></p>
<p>这个已经过时了</p>
<p>定位到按钮</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103203310937.png" alt="image-20240103203310937"></p>
<p>class有两个标签纸</p>
<p>随便填一个就行</p>
<p>就此就可以完成搜索的任务</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.service <span class="keyword">import</span> Service</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line">service=Service(<span class="string">&quot;msedgedriver.exe&quot;</span>)</span><br><span class="line">driver=webdriver.Edge(service=service)</span><br><span class="line">driver.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>)</span><br><span class="line"><span class="comment">#向搜索框录入指定的词</span></span><br><span class="line"><span class="comment">#先找到搜索框</span></span><br><span class="line"><span class="comment">#标签定位</span></span><br><span class="line">search_input=driver.find_element(By.ID,value=<span class="string">&quot;q&quot;</span>)</span><br><span class="line"><span class="comment">#标签的交互</span></span><br><span class="line">search_input.send_keys(<span class="string">&#x27;ipone&#x27;</span>)</span><br><span class="line"><span class="comment">#需要点击搜索按钮</span></span><br><span class="line">search_input2=driver.find_element(By.CLASS_NAME,value=<span class="string">&#x27;btn-search&#x27;</span>)</span><br><span class="line">search_input2.click()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>滚轮的操作</p>
<p>我们可以在控制台里z执行js代码从而实现滚轮的向下滑动</p>
<p>window.scrollTo(0,document.body.scrollHeight)</p>
<p>0是水平的像素</p>
<p>document.body.scrollHeight：是滑动一瓶的距离</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103204137700.png" alt="image-20240103204137700"></p>
<p>这样就实现了滚轮的滑动</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103204137700-17042857240361.png"></p>
<p>最新版的执行js的代码找不到了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.service <span class="keyword">import</span> Service</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line">service=Service(<span class="string">&quot;msedgedriver.exe&quot;</span>)</span><br><span class="line">driver=webdriver.Edge(service=service)</span><br><span class="line">driver.get(<span class="string">&#x27;https://www.taobao.com/&#x27;</span>)</span><br><span class="line"><span class="comment">#向搜索框录入指定的词</span></span><br><span class="line"><span class="comment">#先找到搜索框</span></span><br><span class="line"><span class="comment">#标签定位</span></span><br><span class="line">search_input=driver.find_element(By.ID,value=<span class="string">&quot;q&quot;</span>)</span><br><span class="line"><span class="comment">#标签的交互</span></span><br><span class="line">search_input.send_keys(<span class="string">&#x27;ipone&#x27;</span>)</span><br><span class="line"><span class="comment">#需要点击搜索按钮</span></span><br><span class="line"><span class="comment">#执行js代码</span></span><br><span class="line"><span class="comment"># search_input._execute(&#x27;window.scrollTo(0,document.body.scrollHeight)&#x27;,)</span></span><br><span class="line"><span class="comment"># time.sleep(5)</span></span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">search_input2=driver.find_element(By.CLASS_NAME,value=<span class="string">&#x27;btn-search&#x27;</span>)</span><br><span class="line">search_input2.click()</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">driver.get(<span class="string">&quot;https://baidu.com&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#执行回退的操作</span></span><br><span class="line">driver.back()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#前进</span></span><br><span class="line">driver.forward()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h5 id="selenium处理iframe"><a href="#selenium处理iframe" class="headerlink" title="selenium处理iframe"></a>selenium处理iframe</h5><p>在页面中嵌套子页面</p>
<p>就是页面中常见的滑块验证</p>
<p>拖拽的操作</p>
<p>定位滑块发现</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103210624935.png" alt="image-20240103210624935"></p>
<p>在一个iframe标签下</p>
<p>对应是一个子页面</p>
<p>定位的标签是存在iframe中普通方法是找不到的</p>
<p>需要这样</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103210813811.png" alt="image-20240103210813811"></p>
<p>切换作用域</p>
<p>切换到iframe里面</p>
<p>在就去搜索标签</p>
<p>我还是不用最新版的把</p>
<p>重新安装旧版本的 </p>
<p>更改后的搜索东西</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">bro=webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;https://baidu.com&#x27;</span>)</span><br><span class="line">page_text=bro.page_source</span><br><span class="line">search_input=bro.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)<span class="comment">#定位到搜索框</span></span><br><span class="line">search_input.send_keys(<span class="string">&#x27;王昌晨&#x27;</span>)<span class="comment">#标签的交互</span></span><br><span class="line"><span class="comment">#按</span></span><br><span class="line">btm=bro.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line">btm.click()</span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>滚轮的滑动</p>
<p>滚轮拖动的代码</p>
<p>window.scrollTo(0,document.body.scrollHeight)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">bro=webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;https://baidu.com&#x27;</span>)</span><br><span class="line">page_text=bro.page_source</span><br><span class="line">search_input=bro.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)<span class="comment">#定位到搜索框</span></span><br><span class="line">search_input.send_keys(<span class="string">&#x27;王昌晨&#x27;</span>)<span class="comment">#标签的交互</span></span><br><span class="line"><span class="comment">#按</span></span><br><span class="line">btm=bro.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line">btm.click()</span><br><span class="line"><span class="comment"># 执行js代码</span></span><br><span class="line"><span class="comment"># time.sleep(1)</span></span><br><span class="line">bro.execute_script(<span class="string">&#x27;window.scrollTo(0,document.body.scrollHeight)&#x27;</span>)</span><br><span class="line"><span class="comment"># time.sleep(2)</span></span><br><span class="line">bro.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line">bro.back()</span><br><span class="line">bro.forward()</span><br></pre></td></tr></table></figure>

<p>真的很简单旧版的</p>
<p>iframe的处理</p>
<p>页面嵌套子页面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line">bro=webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;https://baidu.com&#x27;</span>)</span><br><span class="line">page_text=bro.page_source</span><br><span class="line">search_input=bro.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)<span class="comment">#定位到搜索框</span></span><br><span class="line">search_input.send_keys(<span class="string">&#x27;王昌晨&#x27;</span>)<span class="comment">#标签的交互</span></span><br><span class="line"><span class="comment">#按</span></span><br><span class="line">btm=bro.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line">btm.click()</span><br><span class="line"><span class="comment"># 执行js代码</span></span><br><span class="line"><span class="comment"># time.sleep(1)</span></span><br><span class="line">bro.execute_script(<span class="string">&#x27;window.scrollTo(0,document.body.scrollHeight)&#x27;</span>)</span><br><span class="line"><span class="comment"># time.sleep(2)</span></span><br><span class="line">bro.get(<span class="string">&#x27;https://www.taobao.com&#x27;</span>)</span><br><span class="line">bro.back()</span><br><span class="line">bro.forward()</span><br><span class="line">bro.switch_to_frame(<span class="string">&#x27;iframe.&#x27;</span>)<span class="comment">#iframe的标签的属性值</span></span><br><span class="line"><span class="comment"># 动作链</span></span><br><span class="line">action=ActionChains(bro)</span><br><span class="line">action.click_and_hold(<span class="string">&#x27;div&#x27;</span>) <span class="comment">#点击长按指定的标签</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    action.move_by_offset(<span class="number">17</span>,<span class="number">0</span>).perform()<span class="comment">#进行拖动#perform让动作连立刻执行</span></span><br><span class="line">    sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#释放动作连</span></span><br><span class="line">action.release()</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>

<p>#实现模拟登陆</p>
<p>qq空间</p>
<p>代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">bro=webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line">bro.get(<span class="string">&#x27;https://qzone.qq.com/&#x27;</span>)</span><br><span class="line"><span class="comment"># time.sleep(3)</span></span><br><span class="line">bro.switch_to_frame(<span class="string">&#x27;login_frame&#x27;</span>)<span class="comment">#点击密码登录的按键在iframe下</span></span><br><span class="line">click_input=bro.find_element_by_id(<span class="string">&#x27;switcher_plogin&#x27;</span>)</span><br><span class="line">click_input.click()</span><br><span class="line">username=bro.find_element_by_id(<span class="string">&#x27;u&#x27;</span>)</span><br><span class="line"><span class="comment">#实现标签的交互</span></span><br><span class="line">username.send_keys(<span class="string">&#x27;3445883193&#x27;</span>)</span><br><span class="line">password=bro.find_element_by_id(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line">password.send_keys(<span class="string">&#x27;wei3588559&#x27;</span>)</span><br><span class="line">login_btm=bro.find_element_by_id(<span class="string">&#x27;login_button&#x27;</span>)</span><br><span class="line">login_btm.click()</span><br><span class="line"></span><br><span class="line">time.sleep(<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>

<p>但是qq空间做了验证登录不进去</p>
<h5 id="无头浏览器规避检测"><a href="#无头浏览器规避检测" class="headerlink" title="无头浏览器规避检测"></a>无头浏览器规避检测</h5><p>让浏览器的弹出没有可视化的效果</p>
<p>通俗的就是说让浏览器不出来</p>
<p>也叫做无头浏览器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.options <span class="keyword">import</span> Options<span class="comment"># 实现无可视化界面的操作,</span></span><br><span class="line"><span class="comment">#定义浏览器对象</span></span><br><span class="line"><span class="comment">#实现无可视化界面的操作,无可视化界面（无头浏览器）,要用直接复制，加上上面的引入</span></span><br><span class="line">options = Options()<span class="comment">#定义一个option对象</span></span><br><span class="line">options.add_argument(<span class="string">&quot;headless&quot;</span>)</span><br><span class="line"></span><br><span class="line">browser = webdriver.Edge(options = options)</span><br></pre></td></tr></table></figure>

<p>代码如下需要用的时候直接cv就可以</p>
<p>整了半天发现edge的无头设置不了</p>
<p>所以有安装了chorme的驱动</p>
<p>好好好不要太相信ai直接把，我们selenium包给崩了</p>
<p>还是先不设置无头了</p>
<p>实在搞不来</p>
<p>好的继续</p>
<p>那么如何规避掉selenium被检测的风险呢？</p>
<p>好好好还是重新学习把</p>
<p>4以上版本的无头代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="comment"># 无可视化界面设置 #</span></span><br><span class="line">edge_options = Options()</span><br><span class="line"><span class="comment"># 使用无头模式</span></span><br><span class="line">edge_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line"><span class="comment"># 禁用GPU，防止无头模式出现莫名的BUG</span></span><br><span class="line">edge_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"><span class="comment"># 将参数传给浏览器</span></span><br><span class="line">bro = webdriver.Edge(options=edge_options)</span><br><span class="line">bro.get(<span class="string">&#x27;https://qzone.qq.com/&#x27;</span>)</span><br><span class="line">bro.switch_to.frame(<span class="string">&#x27;login_frame&#x27;</span>)</span><br><span class="line">click_input=bro.find_element(By.ID,value=<span class="string">&#x27;switcher_plogin&#x27;</span>)<span class="comment"># 定位后面是id的属性值</span></span><br><span class="line">click_input.click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>



<p>可视化输入账号</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="comment"># 无可视化界面设置 #</span></span><br><span class="line">edge_options = Options()</span><br><span class="line"><span class="comment"># # 使用无头模式</span></span><br><span class="line"><span class="comment"># edge_options.add_argument(&#x27;--headless&#x27;)</span></span><br><span class="line"><span class="comment"># # 禁用GPU，防止无头模式出现莫名的BUG</span></span><br><span class="line"><span class="comment"># edge_options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class="line"><span class="comment"># 将参数传给浏览器</span></span><br><span class="line">bro = webdriver.Edge(options=edge_options)</span><br><span class="line">bro.get(<span class="string">&#x27;https://qzone.qq.com/&#x27;</span>)</span><br><span class="line">bro.switch_to.frame(<span class="string">&#x27;login_frame&#x27;</span>)</span><br><span class="line">click_input=bro.find_element(By.ID,value=<span class="string">&#x27;switcher_plogin&#x27;</span>)<span class="comment"># 定位后面是id的属性值</span></span><br><span class="line">click_input.click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">username=bro.find_element(By.ID,value=<span class="string">&#x27;u&#x27;</span>)</span><br><span class="line">username.send_keys(<span class="string">&#x27;3445883193&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>

<p>然后规避检测的代码如下</p>
<p>再次实现qq登陆的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">from</span> msedge.selenium_tools <span class="keyword">import</span> EdgeOptions</span><br><span class="line"><span class="keyword">from</span> msedge.selenium_tools <span class="keyword">import</span> Edge</span><br><span class="line">edge_options = Options()</span><br><span class="line">edge_options.use_chromium = <span class="literal">True</span></span><br><span class="line">edge_options.add_argument(<span class="string">&#x27;--disable-blink-features=AutomationControlled&#x27;</span>)</span><br><span class="line"><span class="comment"># # 使用无头模式</span></span><br><span class="line"><span class="comment"># edge_options.add_argument(&#x27;--headless&#x27;)</span></span><br><span class="line"><span class="comment"># # 禁用GPU，防止无头模式出现莫名的BUG</span></span><br><span class="line"><span class="comment"># edge_options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class="line"><span class="comment"># 将参数传给浏览器</span></span><br><span class="line">bro = webdriver.Edge(options=edge_options)</span><br><span class="line">bro.get(<span class="string">&#x27;https://qzone.qq.com/&#x27;</span>)</span><br><span class="line">bro.switch_to.frame(<span class="string">&#x27;login_frame&#x27;</span>)</span><br><span class="line">click_input=bro.find_element(By.ID,value=<span class="string">&#x27;switcher_plogin&#x27;</span>)<span class="comment"># 定位后面是id的属性值</span></span><br><span class="line">click_input.click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">username=bro.find_element(By.ID,value=<span class="string">&#x27;u&#x27;</span>)</span><br><span class="line">username.send_keys(<span class="string">&#x27;3445883193&#x27;</span>)</span><br><span class="line">password=bro.find_element(By.ID,value=<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line">password.send_keys(<span class="string">&#x27;wei3588559&#x27;</span>)</span><br><span class="line">click_btm=bro.find_element(By.ID,value=<span class="string">&#x27;login_button&#x27;</span>)</span><br><span class="line">click_btm.click()</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>

<p>每次把</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> selenium</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">from</span> msedge.selenium_tools <span class="keyword">import</span> EdgeOptions</span><br><span class="line"><span class="keyword">from</span> msedge.selenium_tools <span class="keyword">import</span> Edge</span><br><span class="line">edge_options = Options()</span><br><span class="line">edge_options.use_chromium = <span class="literal">True</span></span><br><span class="line">edge_options.add_argument(<span class="string">&#x27;--disable-blink-features=AutomationControlled&#x27;</span>)</span><br><span class="line"><span class="comment"># # 使用无头模式</span></span><br><span class="line">edge_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line"><span class="comment"># 禁用GPU，防止无头模式出现莫名的BUG</span></span><br><span class="line">edge_options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"><span class="comment"># 将参数传给浏览器</span></span><br><span class="line">bro = webdriver.Edge(options=edge_options)</span><br></pre></td></tr></table></figure>

<p>复制在开头就可以</p>
<p>进行12306的模拟登录</p>
<p>​	识别<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104114755203.png" alt="image-20240104114755203"></p>
<p>这个的模拟登录的话</p>
<p>需要使用超级鹰9004</p>
<p>这样的就可以使用超级硬的<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104115245214.png" alt="image-20240104115245214"></p>
<p>流程 ：</p>
<ol>
<li></li>
</ol>
<p>使用selenium打开登录界面</p>
<ol start="2">
<li><p>对当前打开的selenium进行截图，整张页面</p>
</li>
<li><p>对当前图片的局部区域（验证码部分）进行裁剪</p>
<p>好处：将验证码和模拟登陆一一对应 	 	</p>
<p>如果直接对图片src属性的链接获得图片进行访问的话</p>
<p>验证码就不是之前的验证码了</p>
<p>验证码图片就会刷新</p>
<p>4.使用超级鹰</p>
<p>定位位置的时候需要使用</p>
<p>location需要pillow</p>
<p>pip install pillow</p>
</li>
</ol>
<p>然后确定坐标</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104121646942.png" alt="image-20240104121646942"></p>
<p>第一步定位带img标签的位置</p>
<p>第二部获得左上角坐标的位置</p>
<p>第三步获取长宽</p>
<p>这两步返回的都是元组</p>
<p>然后就可以获取到位置了</p>
<p>再导入</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104121932028.png" alt="image-20240104121932028">Image对象</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104121957894.png" alt="image-20240104121957894"></p>
<p>crop根据指定位置进行裁剪</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104124907941.png" alt="image-20240104124907941"></p>
<p>这样就可以获取到图片了</p>
<p>就会返回对应的坐标</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104125405282.png" alt="image-20240104125405282"></p>
<p>然后对验证码进行点击</p>
<p>然后导入动作链</p>
<h4 id="scrapy框架"><a href="#scrapy框架" class="headerlink" title="scrapy框架"></a>scrapy框架</h4><p>什么是框架？</p>
<p>就是集成 了很多功能并且具有很强的通用型的一个项目模板。</p>
<p>项目的半成品</p>
<p>如何学习框架？</p>
<p>专门学习框架封装的各种功能的详细用法</p>
<p>什么是scrapy？</p>
<p>爬虫中封装好的一个明星框架。</p>
<p>具有的功能强大</p>
<p>了解封装了哪些功能</p>
<p>功能？</p>
<p>1.高性能的持久化存储。</p>
<p>2.异步数据的同步下载</p>
<p>3.封装了高性能的数据解析</p>
<p>4.分布式</p>
<h6 id="scrapy的基本使用"><a href="#scrapy的基本使用" class="headerlink" title="scrapy的基本使用"></a>scrapy的基本使用</h6><p>环境的安装：</p>
<p>pip install scrapy</p>
<p>我的就直接安装成功了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104131202387.png" alt="image-20240104131202387"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104131320347.png" alt="image-20240104131320347"></p>
<p>前面几个模块也要安装</p>
<p>我的直接在pycharm上安装了</p>
<p>使用流程</p>
<p>1.创建工程</p>
<p>需要在终端中执行</p>
<p>scrapy startproject 项目名称</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104132214522.png" alt="image-20240104132214522"></p>
<p>目录文件</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104132432587.png" alt="image-20240104132432587"></p>
<p>spiders是爬虫文件夹</p>
<p>里卖弄需要方爬虫文件</p>
<p>spiders子目录创建一个爬虫文件</p>
<p>先进入工程文件</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104132920408.png" alt="image-20240104132920408"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104133009742.png" alt="image-20240104133009742"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104133044962.png" alt="image-20240104133044962"></p>
<p>这样就成功创建了一个名字为spiderName的爬虫文件</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104133209740.png" alt="image-20240104133209740"></p>
<p>然后就可以进行相关代码的编写</p>
<p>如果所有的工程代码都完成了</p>
<p>然后就可以执行工程代码：scrapy crawl +那个创建的名称</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104134628414.png" alt="image-20240104134628414"></p>
<p>爬虫文件代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpidernameSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;spiderName&quot;</span><span class="comment">#爬虫文件名称：爬虫源文件的唯一标识</span></span><br><span class="line">    <span class="comment">#一般下面的这一项会被注释掉</span></span><br><span class="line">    <span class="comment">#allowed_domains = [&quot;www.baidu.com&quot;]#允许的域名 ：限制start——url里的哪些url可以发送</span></span><br><span class="line">    start_urls = [<span class="string">&quot;https://www.baidu.com&quot;</span>,<span class="string">&quot;https://www.taobao.com&quot;</span>]<span class="comment">#起始的url列表：该列表的url会被scrapy自动进行请求的发送</span></span><br><span class="line"><span class="comment">#用做与数据解析：   response参数表示的就是请求成功后对应的响应对象</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="built_in">print</span>(response)<span class="comment">#z这样就会调用两次回复两个response因为上面有两个url</span></span><br></pre></td></tr></table></figure>

<p>然后执行以后</p>
<p>发现打印并不是response而是日志</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104134811313.png" alt="image-20240104134811313"></p>
<p>因为配置文件</p>
<p>需要把<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104135024813.png" alt="image-20240104135024813"></p>
<p>robots</p>
<p>君子协议爬不到的需要改为False</p>
<p>再次执行命令 </p>
<p>发现</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104162655206.png" alt="image-20240104162655206"></p>
<p>还有日志信息</p>
<p>我们可以添加参数不打印日志</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104163051906.png" alt="image-20240104163051906"><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104163223983.png" alt="image-20240104163223983"></p>
<p>但是程序如果有错误的话就不会显示任何东西</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104163329323.png" alt="image-20240104163329323"></p>
<p>在配置文件中可以</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104163329323-17043572242651.png"></p>
<p>这样就可以只显示错误的日志</p>
<p> <img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104172149517.png" alt="image-20240104172149517"></p>
<p>xpath发布会是列表</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104172507136.png" alt="image-20240104172507136"></p>
<p>因为span下面还有标签所以获取到文本需要使用text（）并且它返回的是一个列表这里的xpath返回的是一个对象，如果想把它变成字符串的话就需要使用extract这个方法</p>
<p>如果列表是用来这个方法的话</p>
<p>返回的是一个列表</p>
<p>所以我们需要使用join的方法四列表转为字符串</p>
<p>或者</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104172930705.png" alt="image-20240104172930705"></p>
<p>保证列表中只有一个元素话就可以使用这个方法 </p>
<p>scrapy实现数据解析</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104173020746.png" alt="image-20240104173020746"></p>
<p>scrapy实现持久化存储</p>
<p>1.基于终端指令</p>
<p>-要求只可以将parse方法的返回值存储到本地的文本文件中</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104173401610.png" alt="image-20240104173401610"></p>
<p>这样写</p>
<p>再在终端里面这写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104173506980.png" alt="image-20240104173506980"></p>
<p>注意持久化存储</p>
<p>只能有</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104173555585.png" alt="image-20240104173555585"></p>
<p>一般就是csv或者json</p>
<p>演示的操作</p>
<p>如果爬取这个</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104182934971.png" alt="image-20240104182934971"></p>
<p>代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpidernameSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;spiderName&quot;</span><span class="comment">#爬虫文件名称：爬虫源文件的唯一标识</span></span><br><span class="line">    <span class="comment">#一般下面的这一项会被注释掉</span></span><br><span class="line">    <span class="comment">#allowed_domains = [&quot;www.baidu.com&quot;]#允许的域名 ：限制start——url里的哪些url可以发送</span></span><br><span class="line">    start_urls = [<span class="string">&quot;https://so.gushiwen.cn/guwen/book_46653FD803893E4F7F702BCF1F7CCE17.aspx&quot;</span>]<span class="comment">#起始的url列表：该列表的url会被scrapy自动进行请求的发送</span></span><br><span class="line"><span class="comment">#用做与数据解析：   response参数表示的就是请求成功后对应的响应对象</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">      njr=response.xpath(<span class="string">&#x27;/html/body/div[2]/div[1]/div[2]/div[1]/p//text()&#x27;</span>).extract()</span><br><span class="line">      con=<span class="string">&#x27;&#x27;</span>.join(njr)</span><br><span class="line">      <span class="comment"># print(con)</span></span><br><span class="line">      <span class="keyword">return</span> con</span><br></pre></td></tr></table></figure>

<p>执行的命令</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104183047739.png" alt="image-20240104183047739"></p>
<p>好处</p>
<p>简洁高效</p>
<p>缺点</p>
<p>局限比较强</p>
<p>2.基于管道的方法 </p>
<p>操作复杂</p>
<p>编码流程</p>
<p>1.数据解析</p>
<p>2.在item类中定义相关的属性</p>
<p>items.py里面</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104174108684.png" alt="image-20240104174108684"></p>
<p>把需要储存的这样写</p>
<p>根据上面的例子</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104183239871.png" alt="image-20240104183239871"></p>
<p>3.将解析的数据封装到item类型对象</p>
<p>4.将item类的对象提交给管道进行持久化存储</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104183421900.png" alt="image-20240104183421900"></p>
<p>管道类中process——item 将接受到item对象进行存储</p>
<p>5.在配置文件中手动开启管道</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104190710575.png" alt="image-20240104190710575"></p>
<p>里面的300表表示优先级，越小优先级越高	</p>
<p>实践走起</p>
<p>项目里的</p>
<p>njr1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="comment">#基于管道的持久化存储的操作</span></span><br><span class="line"><span class="comment">#导入item</span></span><br><span class="line"><span class="keyword">from</span> njr.items <span class="keyword">import</span> NjrItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Njr1Spider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;njr1&quot;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&quot;www.baidu.com&quot;]</span></span><br><span class="line">    start_urls = [<span class="string">&quot;https://so.gushiwen.cn/guwen/book_46653FD803893E4F7F702BCF1F7CCE17.aspx&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        text = response.xpath(<span class="string">&#x27;/html/body/div[2]/div[1]/div[2]/div[1]/p//text()&#x27;</span>).extract()</span><br><span class="line">        con = <span class="string">&#x27;&#x27;</span>.join(text)</span><br><span class="line">        <span class="built_in">print</span>(con)</span><br><span class="line">        <span class="comment"># pass</span></span><br><span class="line">        <span class="comment">#实列话引入的对象</span></span><br><span class="line">        item=NjrItem()</span><br><span class="line">        <span class="comment">#将item的数据封装到</span></span><br><span class="line">        item[<span class="string">&#x27;con&#x27;</span>]=con</span><br><span class="line"><span class="comment">#将item提交给管道</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p>面试题：</p>
<p>将爬到的数据一份存在本地一份存在数据库，如何实现？</p>
<p>使用管道</p>
<p>实现的方法：</p>
<p>在管道文件中再定义一个类</p>
<p>现在管道文件中</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104192015598.png" alt="image-20240104192015598"></p>
<p>导入库</p>
<p>管道的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NjrPipeline</span>:</span><br><span class="line">    fp=<span class="literal">None</span></span><br><span class="line">    <span class="comment">#重写一个父类的一个方法：该方法只在开始怕从的时候被调用一次</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self,spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;开始爬虫&#x27;</span>)</span><br><span class="line">        self.fp=<span class="built_in">open</span>(<span class="string">&#x27;./三国1scary .txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        con=item[<span class="string">&#x27;con&#x27;</span>]<span class="comment">#接受值</span></span><br><span class="line">        <span class="comment">#进行存储</span></span><br><span class="line">        self.fp.write(con)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self,spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;over&#x27;</span>)</span><br><span class="line">        self.fp.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"><span class="comment">#将一份存在数据库中</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">mysqlPipeline</span>():</span><br><span class="line">    <span class="comment">#可以把连接数据库放到这里</span></span><br><span class="line">    conn=<span class="literal">None</span></span><br><span class="line">    cursor=<span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self,spider</span>):<span class="comment">#这个函数只会在开始的时候执行</span></span><br><span class="line">        self.conn=pymysql.connect(host=<span class="string">&#x27;127.0.0.1&#x27;</span>,port=<span class="number">3306</span>,user=<span class="string">&#x27;root&#x27;</span>,password=<span class="string">&#x27;123456&#x27;</span>,db=<span class="string">&#x27;pycharm&#x27;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):</span><br><span class="line">        self.conn.cursor()</span><br><span class="line">        self.cursor.execute(<span class="string">&#x27;insert into 111 value(&quot;%s&quot;)%(con)&#x27;</span>)</span><br><span class="line">        self.conn.commit()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self,spider</span>):</span><br><span class="line">        self.cursor.close()</span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure>

<p>配置文件中还需要添加</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240104194654525.png" alt="image-20240104194654525"></p>
<p>算了放弃了</p>
<p>然后就是</p>
<p>yield scrapy.Request(url,callback&#x3D;self.)</p>
<p>对解析出的url在进行解析数据</p>
<h5 id="scrapy图片数据的爬取"><a href="#scrapy图片数据的爬取" class="headerlink" title="scrapy图片数据的爬取"></a>scrapy图片数据的爬取</h5><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240106173027434.png" alt="image-20240106173027434"></p>
<p>实践</p>
<p>发现请求的数据是none原因是因为</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240106173651679.png" alt="image-20240106173651679"></p>
<p>src2是伪属性</p>
<p>如果舒勇src2的话</p>
<p>请求的页面不会显示在前端也不会有显示</p>
<p>发现大部分的图片是src2</p>
<p>发现只有当前页面显示的src是src</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240106174009621.png" alt="image-20240106174009621"></p>
<p>没有显示出来的是src2</p>
<p>只有真正src属性才可以显示在有可视化界面</p>
<p>因为scrapy请求没有可视化界面 所以就不可以获取到</p>
<p>只要把src换成src2才可以</p>
<p>要使用为属性 </p>
<p>如果是图片的话</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240106174609652.png" alt="image-20240106174609652"></p>
<p>管道类的这个就不能在使用了</p>
<p>用imagesPipeline</p>
<p>上面的问题我在爬站长之家的时候遇到了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240106180902317.png" alt="image-20240106180902317"></p>
<p>懒加载</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E6%8A%93%E5%8F%96%E7%BD%91%E5%90%A7%E7%94%B5%E5%BD%B1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E6%8A%93%E5%8F%96%E7%BD%91%E5%90%A7%E7%94%B5%E5%BD%B1/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-08 14:23:16" itemprop="dateModified" datetime="2024-01-08T14:23:16+08:00">2024-01-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="抓取网吧电影"><a href="#抓取网吧电影" class="headerlink" title="抓取网吧电影"></a>抓取网吧电影</h1><p>网站怎么爬取 视频</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107191215370.png" alt="image-20240107191215370"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107191237332.png" alt="image-20240107191237332"></p>
<p>几乎没有网站在video直接方视频的地址</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107191329450.png" alt="image-20240107191329450"></p>
<p>因为加载会加载很大，就会导致</p>
<p>用户体验很差</p>
<p>造成资源</p>
<p>所以进行切片处理：吧大视频切成好几篇</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107191651139.png" alt="image-20240107191651139"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107191832936.png" alt="image-20240107191832936"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107192016817.png" alt="image-20240107192016817"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107192206532.png" alt="image-20240107192206532"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240107192259902.png" alt="image-20240107192259902"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-02 09:41:33" itemprop="dateModified" datetime="2024-01-02T09:41:33+08:00">2024-01-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h1><h5 id="原理概念"><a href="#原理概念" class="headerlink" title="原理概念"></a>原理概念</h5><p>聚焦爬虫：爬取页面指定的内容。</p>
<h5 id="数据分析分类"><a href="#数据分析分类" class="headerlink" title="数据分析分类"></a>数据分析分类</h5><h6 id="基于正则"><a href="#基于正则" class="headerlink" title="基于正则"></a>基于正则</h6><h6 id="基于bs46"><a href="#基于bs46" class="headerlink" title="基于bs46"></a>基于bs46</h6><h6 id="xpath-学习的重点-通用性强其它语言的爬虫也适用"><a href="#xpath-学习的重点-通用性强其它语言的爬虫也适用" class="headerlink" title="xpath(学习的重点)通用性强其它语言的爬虫也适用"></a>xpath(学习的重点)通用性强其它语言的爬虫也适用</h6><h5 id="数据解析的大致原理"><a href="#数据解析的大致原理" class="headerlink" title="数据解析的大致原理"></a>数据解析的大致原理</h5><p>指定局部的页面内容</p>
<p>例如我们提取的页面信息有可能在标签中，标签对应的属性中</p>
<p>也有可能在标签中的超链接中</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231140757216.png" alt="image-20231231140757216"></p>
<p>1.进行指定标签的定位</p>
<p>2.标签对应的属性值进行提取（解析)</p>
<p>流程：</p>
<p>1指定url</p>
<p>2.发起请求</p>
<p>3.获取响应数据</p>
<p>4.数据解析</p>
<p>5.持久化储存</p>
<h6 id="使用正则进行数据解析"><a href="#使用正则进行数据解析" class="headerlink" title="使用正则进行数据解析"></a>使用正则进行数据解析</h6><p>需求爬取糗事百科中囚徒板块下所有糗图的图片</p>
<p>这次需要爬取图片</p>
<p>如何爬取图片？</p>
<p>我们可以这样打开图片</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231151600316.png" alt="image-20231231151600316"></p>
<p>所以就可以利用url进行对文件资源的读写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231152730742.png" alt="image-20231231152730742"></p>
<p>之前读取的都是文本文件用text</p>
<p>这此时图片我们需要使用content获取二进制新形势的图片数据</p>
<p>text（字符串）context（二进制）json（对象） </p>
<p>代码如下</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153148626.png" alt="image-20231231153148626"></p>
<p>注意：在都写文件的时候需要使用wb：在 Python 中，打开文件时需要指定文件模式(mode)，以说明文件的打开方式和用途。其中，<code>w</code> 模式表示写入文本数据，而 <code>wb</code> 模式则表示写入二进制数据。在写入二进制数据时，需要使用 <code>wb</code> 模式，因为二进制数据中可能包含各种字节，例如 0x00、0x0A 等，这些字节在文本文件中有可能会被解释成特殊字符或控制字符，导致数据出现错误。通过使用 <code>wb</code> 模式打开文件，Python 会将数据原封不动地写入到文件中，而不做任何额外的转换或解释。这样可以确保写入的数据与原始数据完全一致，避免出现意外的错误。、</p>
<p>这样我们就成功返回二进制的图片数据</p>
<p>1：解题过程</p>
<p>没有这个网站，所以而我换了有一个网站再继续尝试</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153632747.png" alt="image-20231231153632747"></p>
<p>第一步：获取整张数据</p>
<p>第二步：使用聚焦爬虫将页面中的图片进行爬取</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231154347839.png" alt="image-20231231154347839"></p>
<p>定位中图片发现与img图片的src的属性</p>
<p>我们需要把整张页面的img的src进行提取</p>
<p>然后再把每个图片给保存下来</p>
<p>此时就需要使用正则</p>
<p> 演示讲解</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231155235042.png" alt="image-20231231155235042"></p>
<p>构造正则</p>
<p>那是观察页面的源码发现一个大的div标签中有很多的小的div</p>
<p>每一个小的div中含有相同的上面源码的代码</p>
<p>所以就这样构造正则</p>
<p>利用正则组要使用re.findall()函数</p>
<p>re.findall()<code>是 Python 中</code>re&#96; 模块提供的一个函数，用于在字符串中查找匹配某个正则表达式的所有子串，并以列表的形式返回所有匹配结果。</p>
<p>具体来说，<code>re.findall(pattern, string)</code> 函数会在 <code>string</code> 字符串中查找所有与 <code>pattern</code> 正则表达式匹配的子串，并将它们全部存入一个列表中返回。如果没有匹配的结果，则返回空列表。</p>
<p>例如，下面的代码演示了如何使用 <code>re.findall()</code> 查找一个字符串中所有的数字：</p>
<p>[Python re.findall中正则表达式(.*?)和参数re.S使用_re</p>
<p>[]: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36556893/article/details/89182067?ops_request_misc=&request_id=&biz_id=102&utm_term=re.findall()%E8%AF%AD%E6%B3%95re.S&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduweb~default-0-89182067.nonecase&spm=1018.2226.3001.4450">.findall()用法 re.s-CSDN博客</a></p>
<p>这里是详情用法</p>
<p>成功</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161155362.png" alt="image-20231231161155362"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161209460.png" alt="image-20231231161209460"></p>
<p>然后在对列表中每个连接进行get请求</p>
<p>然后就是对图片数据进行保存</p>
<p>我们先导入os模块创建文件夹</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161815963.png" alt="image-20231231161815963"></p>
<pre><code> 规定生成的图片名称
</code></pre>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161716409.png" alt="image-20231231161716409"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161850579.png" alt="image-20231231161850579"></p>
<p>然后后面的过程就知道了‘</p>
<p>在设置一个循环把多页的数据都给提出来</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231164118700.png" alt="image-20231231164118700"></p>
<p>over</p>
<h5 id="bs4（python独有的）进行数据-解析"><a href="#bs4（python独有的）进行数据-解析" class="headerlink" title="bs4（python独有的）进行数据 解析"></a>bs4（python独有的）进行数据 解析</h5><p>1.定位标签</p>
<p>2.提取标签</p>
<h6 id="bs4的原理"><a href="#bs4的原理" class="headerlink" title="bs4的原理"></a>bs4的原理</h6><p>1.实例化一个beatifulsoup对象，并且将页面源码数据加载到该对象中</p>
<p>2.通过调用beatifulsoup对象中相关的属性或者方法进行标签定位和数据提取</p>
<p>环境的配置：</p>
<p>pip install bs4</p>
<p>pip install lxml  	 	</p>
<p>如何实例化beatiful对象呢</p>
<p>from bs4 import BeautifulSoup</p>
<p>在操作的时候会遇到的问题</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231170252005.png" alt="image-20231231170252005"></p>
<p>把文件的名字bs4修改以下</p>
<p>因为他会在这个文件下寻找</p>
<p>对象的实例化：1.将本地的html页面加载到该对象中</p>
<p>可以发现我们打印是一个对象，对象之中存储的就是本地html的源码的内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br></pre></td></tr></table></figure>

<p>​							2将互联网上获取的页面源码加载到该对象中</p>
<p>这种方法便捷</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line"><span class="comment"># fp=open(&quot;hututu.html&quot;,&#x27;r&#x27;,encoding=&#x27;utf-8&#x27;)</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(fp,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">response=requests.get(url=url)</span><br><span class="line">page_txt=response.text</span><br><span class="line">soup=BeautifulSoup(page_txt,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231171653454.png" alt="image-20231231171653454"></p>
<p>提供用于数据解析的方法和属性：</p>
<p>1：soup.tagname:对象加上.标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.a)</span><br><span class="line"><span class="comment"># url=&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># response=requests.get(url=url)</span></span><br><span class="line"><span class="comment"># page_txt=response.text</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(page_txt,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br></pre></td></tr></table></figure>

<p>打印a标签的值，但是返回只是第一行</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172309956.png" alt="image-20231231172309956"></p>
<p>2.soup.find:和第一个类似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.p)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;p&#x27;</span>))</span><br><span class="line"><span class="comment"># url=&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># response=requests.get(url=url)</span></span><br><span class="line"><span class="comment"># page_txt=response.text</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(page_txt,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>还有一种用法</p>
<p>属性定位</p>
<p>比如很多个div</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172849098.png" alt="image-20231231172849098"></p>
<p>我想定位第二个div的话</p>
<p>可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;translate211217 trans-common special-subject&quot;</span>))</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231173104989.png" alt="image-20231231173104989"></p>
<p>class后面必须要加上_这样才能认为时属性值</p>
<p>3.soup.find.all:加载全部符合的标签</p>
<p>4.soup.select(“某种选择器”)例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&quot;.arrow&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174021277.png" alt="image-20231231174021277"></p>
<p>第二种用法（层层 的递归）</p>
<p>比如</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174400513.png" alt="image-20231231174400513"></p>
<p>我们想看a标签可以这么写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174443172.png" alt="image-20231231174443172"></p>
<p>一共很多的a标签返回的时列表</p>
<p>我们可以</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174522106.png" alt="image-20231231174522106"></p>
<p>返回第一个标签</p>
<p>或者这么些空格表示多个层级</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174643158.png" alt="image-20231231174643158"></p>
<h6 id="获取标签中的文本数据："><a href="#获取标签中的文本数据：" class="headerlink" title="获取标签中的文本数据："></a>获取标签中的文本数据：</h6><p>soup.a.text&#x2F;string&#x2F;get_text()</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174944883.png" alt="image-20231231174944883"></p>
<p>text string get_text()区别</p>
<p>text&#x2F;get_text()可以获取一个标签的所有文本内容，就比如div标签下有个a标签a标签下有内容，就可以获取的到</p>
<p>string：只可以获取该标签下的直系文本内容</p>
<h6 id="获取标签中的属性值"><a href="#获取标签中的属性值" class="headerlink" title="获取标签中的属性值"></a>获取标签中的属性值</h6><p>soup.a[‘href’]</p>
<p>获取a标签下的属性值的值</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231175718249.png" alt="image-20231231175718249"></p>
<h6 id="实际案列"><a href="#实际案列" class="headerlink" title="实际案列"></a>实际案列</h6><p>爬取三国演义小说所有章节标题和章节内容 </p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231180005482.png" alt="image-20231231180005482"></p>
<p>每一个章节都有一个a标签</p>
<p>解题思路</p>
<p>1.还是先获取整张页面</p>
<p>2.提取章节对应的名称和对应的href值</p>
<p>3.对href地址发送请求拿到详情页的所对应的章节内容提取</p>
<p>源码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.shicimingju.com/book/sanguoyanyi.html&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text</span><br><span class="line">soup=BeautifulSoup(page_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment">#定位到a标签在的地方</span></span><br><span class="line">list_a=soup.select(<span class="string">&#x27;.book-mulu &gt; ul &gt; li&#x27;</span>)</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;sanguo.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_a:</span><br><span class="line">    title=li.a.string</span><br><span class="line">    detail_url=<span class="string">&#x27;https://www.shicimingju.com&#x27;</span>+li.a[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对详情页发起请求,解析春章节内容</span></span><br><span class="line">    detail_text=requests.get(url=detail_url,headers=header).text<span class="comment">#观察源码发现内容保存在class=chapter_content的div标签下此时我们只需要该标签下的全部内容就可以</span></span><br><span class="line">    detail_soup=BeautifulSoup(detail_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    div_tag=detail_soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;chapter_content&quot;</span>)<span class="comment">#解析到章节的内容</span></span><br><span class="line">    content=div_tag.get_text()<span class="comment">#或者txt</span></span><br><span class="line">    fp.write(title+content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取成功&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>爬取的结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231192536782.png" alt="image-20231231192536782"></p>
<p>有些字符串编码问题，先不考虑了</p>
<h5 id="xpath解析（常用高效便捷通用）"><a href="#xpath解析（常用高效便捷通用）" class="headerlink" title="xpath解析（常用高效便捷通用）"></a>xpath解析（常用高效便捷通用）</h5><p>原理：</p>
<p>1.实例化一个ertee的对象,且需要将被解析的页面源码数据加载到该对象。</p>
<p>2.调用ertee对象中的xpath方法结合这xpath的表达式实现标签 的定位和内容的捕获。<br>环境的安装：</p>
<p>pip -install lxml (一款解析器)</p>
<p>如何实现实例化ertee的对象？\</p>
<p>from lxml import etree</p>
<p>1.还是本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">etree.parse(filepath)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.可以将从互联网上个获取的源码家作家到该对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">etree.HTML(<span class="string">&#x27;page_text&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>本地的操练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&#x27;hututu.html&#x27;</span>)<span class="comment">#加载源码到该对象中&#x27;</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;/html/head/title&#x27;</span>)<span class="comment">#根据 层级关系进行定位</span></span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195526560.png" alt="image-20231231195526560"></p>
<p>返回的是</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195559057.png" alt="image-20231231195559057"></p>
<p>xpath是根据层级关系进行定位的，返回的是列表，看不见内容</p>
<p> xpath表达式：</p>
<p>&#x2F;：表示是从根节点开始定位.表示一个层级</p>
<p>&#x2F;&#x2F;：表示的是多个层级】</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200204579.png" alt="image-20231231200204579"></p>
<p>&#x2F;&#x2F;div任意位置开始定位</p>
<p>属性定位：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200340011.png" alt="image-20231231200340011"></p>
<p>定位到的是属性为song的div，有可能多个，所以返回的也是列表</p>
<p>索引定位：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200542490.png" alt="image-20231231200542490"></p>
<p>这个div下有多个p标签</p>
<p>如果获取苏轼所对应的p标签</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200710670.png" alt="image-20231231200710670"></p>
<p>这样就可以了</p>
<p>注意！</p>
<p>注意！</p>
<p>这里的所以是从1开始的</p>
<p>如何取文本？</p>
<p>使用text（）</p>
<p>如何取标签?</p>
<p>例子：</p>
<p>使用&#x2F;@href</p>
<p>忘记保存了之前写的全丢了再简单的记一下</p>
<p>58同城的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化etree对象</span></span><br><span class="line"><span class="comment"># 先爬取整张的页面数据</span></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">&#x27;https://ty.58.com/xiaodian/ershoufang/&#x27;</span></span><br><span class="line">page_text = requests.get(url=url, headers=header).text  <span class="comment"># 获取到源码数据</span></span><br><span class="line">tree = etree.HTML(page_text)  <span class="comment"># 加载到etree对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看源码发现标题都在li下的a标签下所以我们可以把每个li给拿出来在对li在进行提取</span></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//section[@class=&quot;list&quot;]/div&#x27;</span>)</span><br><span class="line">fp = <span class="built_in">open</span>(<span class="string">&#x27;58同城title.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    title = li.xpath(<span class="string">&#x27;./a/div[2]//h3/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 价格</span></span><br><span class="line">    price_list = li.xpath(<span class="string">&#x27;./a/div[2]/div[@class=&quot;property-price&quot;]//text()&#x27;</span>)</span><br><span class="line">    price = <span class="string">&#x27;&#x27;</span>.join(price_list)</span><br><span class="line"></span><br><span class="line">    fp.write(title + <span class="string">&#x27; &#x27;</span> + price + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(title + <span class="string">&#x27; &#x27;</span> + price + <span class="string">&#x27; 保存成功&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>

<p>美女的那个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#创建文件夹</span></span><br><span class="line">filename = <span class="string">&#x27;meitu&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.mkdir(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;创建成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;文件夹已存在&#x27;</span>)</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;http://pic.netbian.com/4kmeinv/&#x27;</span></span><br><span class="line">response_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(response_text)</span><br><span class="line">list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_li:</span><br><span class="line">    new_url = <span class="string">&#x27;https://pic.netbian.com&#x27;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    detail_content = requests.get(url=new_url, headers=header).content</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span><span class="comment">#替换有/和：符号防止保存出错</span></span><br><span class="line">    img_name=name.encode(<span class="string">&#x27;iso-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">    path = os.path.join(filename, img_name)</span><br><span class="line">    <span class="built_in">print</span>(img_name, new_url, path)</span><br><span class="line">    fp = <span class="built_in">open</span>(path, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    fp.write(detail_content)</span><br><span class="line">    fp.close()</span><br></pre></td></tr></table></figure>

<p>这里有要点：</p>
<p>我们在实践中发现中文会出现乱码</p>
<p>解决方案：</p>
<p>两种：</p>
<p>第一种：</p>
<p>先对数据包返回的数据进行utf-8编码</p>
<p>如何还是不行</p>
<p>第二种：</p>
<p>先对中文乱码的地方进行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img_name=name.encode(<span class="string">&#x27;iso-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>例如这样的</p>
<p>还有要掌握使用os模块建立文件夹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#创建文件夹</span></span><br><span class="line">filename = <span class="string">&#x27;meitu&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.mkdir(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;创建成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;文件夹已存在&#x27;</span>)</span><br><span class="line">path=os.path.join(filname,<span class="string">&#x27;WENJIAN&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>作业</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%902/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%902/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-02 10:07:58" itemprop="dateModified" datetime="2024-01-02T10:07:58+08:00">2024-01-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h1><h5 id="原理概念"><a href="#原理概念" class="headerlink" title="原理概念"></a>原理概念</h5><p>聚焦爬虫：爬取页面指定的内容。</p>
<h5 id="数据分析分类"><a href="#数据分析分类" class="headerlink" title="数据分析分类"></a>数据分析分类</h5><h6 id="基于正则"><a href="#基于正则" class="headerlink" title="基于正则"></a>基于正则</h6><h6 id="基于bs46"><a href="#基于bs46" class="headerlink" title="基于bs46"></a>基于bs46</h6><h6 id="xpath-学习的重点-通用性强其它语言的爬虫也适用"><a href="#xpath-学习的重点-通用性强其它语言的爬虫也适用" class="headerlink" title="xpath(学习的重点)通用性强其它语言的爬虫也适用"></a>xpath(学习的重点)通用性强其它语言的爬虫也适用</h6><h5 id="数据解析的大致原理"><a href="#数据解析的大致原理" class="headerlink" title="数据解析的大致原理"></a>数据解析的大致原理</h5><p>指定局部的页面内容</p>
<p>例如我们提取的页面信息有可能在标签中，标签对应的属性中</p>
<p>也有可能在标签中的超链接中</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231140757216.png" alt="image-20231231140757216"></p>
<p>1.进行指定标签的定位</p>
<p>2.标签对应的属性值进行提取（解析)</p>
<p>流程：</p>
<p>1指定url</p>
<p>2.发起请求</p>
<p>3.获取响应数据</p>
<p>4.数据解析</p>
<p>5.持久化储存</p>
<h6 id="使用正则进行数据解析"><a href="#使用正则进行数据解析" class="headerlink" title="使用正则进行数据解析"></a>使用正则进行数据解析</h6><p>需求爬取糗事百科中囚徒板块下所有糗图的图片</p>
<p>这次需要爬取图片</p>
<p>如何爬取图片？</p>
<p>我们可以这样打开图片</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231151600316.png" alt="image-20231231151600316"></p>
<p>所以就可以利用url进行对文件资源的读写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231152730742.png" alt="image-20231231152730742"></p>
<p>之前读取的都是文本文件用text</p>
<p>这此时图片我们需要使用content获取二进制新形势的图片数据</p>
<p>text（字符串）context（二进制）json（对象） </p>
<p>代码如下</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153148626.png" alt="image-20231231153148626"></p>
<p>注意：在都写文件的时候需要使用wb：在 Python 中，打开文件时需要指定文件模式(mode)，以说明文件的打开方式和用途。其中，<code>w</code> 模式表示写入文本数据，而 <code>wb</code> 模式则表示写入二进制数据。在写入二进制数据时，需要使用 <code>wb</code> 模式，因为二进制数据中可能包含各种字节，例如 0x00、0x0A 等，这些字节在文本文件中有可能会被解释成特殊字符或控制字符，导致数据出现错误。通过使用 <code>wb</code> 模式打开文件，Python 会将数据原封不动地写入到文件中，而不做任何额外的转换或解释。这样可以确保写入的数据与原始数据完全一致，避免出现意外的错误。、</p>
<p>这样我们就成功返回二进制的图片数据</p>
<p>1：解题过程</p>
<p>没有这个网站，所以而我换了有一个网站再继续尝试</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153632747.png" alt="image-20231231153632747"></p>
<p>第一步：获取整张数据</p>
<p>第二步：使用聚焦爬虫将页面中的图片进行爬取</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231154347839.png" alt="image-20231231154347839"></p>
<p>定位中图片发现与img图片的src的属性</p>
<p>我们需要把整张页面的img的src进行提取</p>
<p>然后再把每个图片给保存下来</p>
<p>此时就需要使用正则</p>
<p> 演示讲解</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231155235042.png" alt="image-20231231155235042"></p>
<p>构造正则</p>
<p>那是观察页面的源码发现一个大的div标签中有很多的小的div</p>
<p>每一个小的div中含有相同的上面源码的代码</p>
<p>所以就这样构造正则</p>
<p>利用正则组要使用re.findall()函数</p>
<p>re.findall()<code>是 Python 中</code>re&#96; 模块提供的一个函数，用于在字符串中查找匹配某个正则表达式的所有子串，并以列表的形式返回所有匹配结果。</p>
<p>具体来说，<code>re.findall(pattern, string)</code> 函数会在 <code>string</code> 字符串中查找所有与 <code>pattern</code> 正则表达式匹配的子串，并将它们全部存入一个列表中返回。如果没有匹配的结果，则返回空列表。</p>
<p>例如，下面的代码演示了如何使用 <code>re.findall()</code> 查找一个字符串中所有的数字：</p>
<p>[Python re.findall中正则表达式(.*?)和参数re.S使用_re</p>
<p>[]: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36556893/article/details/89182067?ops_request_misc=&request_id=&biz_id=102&utm_term=re.findall()%E8%AF%AD%E6%B3%95re.S&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduweb~default-0-89182067.nonecase&spm=1018.2226.3001.4450">.findall()用法 re.s-CSDN博客</a></p>
<p>这里是详情用法</p>
<p>成功</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161155362.png" alt="image-20231231161155362"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161209460.png" alt="image-20231231161209460"></p>
<p>然后在对列表中每个连接进行get请求</p>
<p>然后就是对图片数据进行保存</p>
<p>我们先导入os模块创建文件夹</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161815963.png" alt="image-20231231161815963"></p>
<pre><code> 规定生成的图片名称
</code></pre>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161716409.png" alt="image-20231231161716409"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161850579.png" alt="image-20231231161850579"></p>
<p>然后后面的过程就知道了‘</p>
<p>在设置一个循环把多页的数据都给提出来</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231164118700.png" alt="image-20231231164118700"></p>
<p>over</p>
<h5 id="bs4（python独有的）进行数据-解析"><a href="#bs4（python独有的）进行数据-解析" class="headerlink" title="bs4（python独有的）进行数据 解析"></a>bs4（python独有的）进行数据 解析</h5><p>1.定位标签</p>
<p>2.提取标签</p>
<h6 id="bs4的原理"><a href="#bs4的原理" class="headerlink" title="bs4的原理"></a>bs4的原理</h6><p>1.实例化一个beatifulsoup对象，并且将页面源码数据加载到该对象中</p>
<p>2.通过调用beatifulsoup对象中相关的属性或者方法进行标签定位和数据提取</p>
<p>环境的配置：</p>
<p>pip install bs4</p>
<p>pip install lxml  	 	</p>
<p>如何实例化beatiful对象呢</p>
<p>from bs4 import BeautifulSoup</p>
<p>在操作的时候会遇到的问题</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231170252005.png" alt="image-20231231170252005"></p>
<p>把文件的名字bs4修改以下</p>
<p>因为他会在这个文件下寻找</p>
<p>对象的实例化：1.将本地的html页面加载到该对象中</p>
<p>可以发现我们打印是一个对象，对象之中存储的就是本地html的源码的内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br></pre></td></tr></table></figure>

<p>​							2将互联网上获取的页面源码加载到该对象中</p>
<p>这种方法便捷</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line"><span class="comment"># fp=open(&quot;hututu.html&quot;,&#x27;r&#x27;,encoding=&#x27;utf-8&#x27;)</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(fp,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">response=requests.get(url=url)</span><br><span class="line">page_txt=response.text</span><br><span class="line">soup=BeautifulSoup(page_txt,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231171653454.png" alt="image-20231231171653454"></p>
<p>提供用于数据解析的方法和属性：</p>
<p>1：soup.tagname:对象加上.标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.a)</span><br><span class="line"><span class="comment"># url=&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># response=requests.get(url=url)</span></span><br><span class="line"><span class="comment"># page_txt=response.text</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(page_txt,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br></pre></td></tr></table></figure>

<p>打印a标签的值，但是返回只是第一行</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172309956.png" alt="image-20231231172309956"></p>
<p>2.soup.find:和第一个类似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.p)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;p&#x27;</span>))</span><br><span class="line"><span class="comment"># url=&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># response=requests.get(url=url)</span></span><br><span class="line"><span class="comment"># page_txt=response.text</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(page_txt,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>还有一种用法</p>
<p>属性定位</p>
<p>比如很多个div</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172849098.png" alt="image-20231231172849098"></p>
<p>我想定位第二个div的话</p>
<p>可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;translate211217 trans-common special-subject&quot;</span>))</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231173104989.png" alt="image-20231231173104989"></p>
<p>class后面必须要加上_这样才能认为时属性值</p>
<p>3.soup.find.all:加载全部符合的标签</p>
<p>4.soup.select(“某种选择器”)例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&quot;.arrow&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174021277.png" alt="image-20231231174021277"></p>
<p>第二种用法（层层 的递归）</p>
<p>比如</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174400513.png" alt="image-20231231174400513"></p>
<p>我们想看a标签可以这么写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174443172.png" alt="image-20231231174443172"></p>
<p>一共很多的a标签返回的时列表</p>
<p>我们可以</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174522106.png" alt="image-20231231174522106"></p>
<p>返回第一个标签</p>
<p>或者这么些空格表示多个层级</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174643158.png" alt="image-20231231174643158"></p>
<h6 id="获取标签中的文本数据："><a href="#获取标签中的文本数据：" class="headerlink" title="获取标签中的文本数据："></a>获取标签中的文本数据：</h6><p>soup.a.text&#x2F;string&#x2F;get_text()</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174944883.png" alt="image-20231231174944883"></p>
<p>text string get_text()区别</p>
<p>text&#x2F;get_text()可以获取一个标签的所有文本内容，就比如div标签下有个a标签a标签下有内容，就可以获取的到</p>
<p>string：只可以获取该标签下的直系文本内容</p>
<h6 id="获取标签中的属性值"><a href="#获取标签中的属性值" class="headerlink" title="获取标签中的属性值"></a>获取标签中的属性值</h6><p>soup.a[‘href’]</p>
<p>获取a标签下的属性值的值</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231175718249.png" alt="image-20231231175718249"></p>
<h6 id="实际案列"><a href="#实际案列" class="headerlink" title="实际案列"></a>实际案列</h6><p>爬取三国演义小说所有章节标题和章节内容 </p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231180005482.png" alt="image-20231231180005482"></p>
<p>每一个章节都有一个a标签</p>
<p>解题思路</p>
<p>1.还是先获取整张页面</p>
<p>2.提取章节对应的名称和对应的href值</p>
<p>3.对href地址发送请求拿到详情页的所对应的章节内容提取</p>
<p>源码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.shicimingju.com/book/sanguoyanyi.html&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text</span><br><span class="line">soup=BeautifulSoup(page_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment">#定位到a标签在的地方</span></span><br><span class="line">list_a=soup.select(<span class="string">&#x27;.book-mulu &gt; ul &gt; li&#x27;</span>)</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;sanguo.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_a:</span><br><span class="line">    title=li.a.string</span><br><span class="line">    detail_url=<span class="string">&#x27;https://www.shicimingju.com&#x27;</span>+li.a[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对详情页发起请求,解析春章节内容</span></span><br><span class="line">    detail_text=requests.get(url=detail_url,headers=header).text<span class="comment">#观察源码发现内容保存在class=chapter_content的div标签下此时我们只需要该标签下的全部内容就可以</span></span><br><span class="line">    detail_soup=BeautifulSoup(detail_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    div_tag=detail_soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;chapter_content&quot;</span>)<span class="comment">#解析到章节的内容</span></span><br><span class="line">    content=div_tag.get_text()<span class="comment">#或者txt</span></span><br><span class="line">    fp.write(title+content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取成功&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>爬取的结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231192536782.png" alt="image-20231231192536782"></p>
<p>有些字符串编码问题，先不考虑了</p>
<h5 id="xpath解析（常用高效便捷通用）"><a href="#xpath解析（常用高效便捷通用）" class="headerlink" title="xpath解析（常用高效便捷通用）"></a>xpath解析（常用高效便捷通用）</h5><p>原理：</p>
<p>1.实例化一个ertee的对象,且需要将被解析的页面源码数据加载到该对象。</p>
<p>2.调用ertee对象中的xpath方法结合这xpath的表达式实现标签 的定位和内容的捕获。<br>环境的安装：</p>
<p>pip -install lxml (一款解析器)</p>
<p>如何实现实例化ertee的对象？\</p>
<p>from lxml import etree</p>
<p>1.还是本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">etree.parse(filepath)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.可以将从互联网上个获取的源码家作家到该对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">etree.HTML(<span class="string">&#x27;page_text&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>本地的操练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&#x27;hututu.html&#x27;</span>)<span class="comment">#加载源码到该对象中&#x27;</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;/html/head/title&#x27;</span>)<span class="comment">#根据 层级关系进行定位</span></span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195526560.png" alt="image-20231231195526560"></p>
<p>返回的是</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195559057.png" alt="image-20231231195559057"></p>
<p>xpath是根据层级关系进行定位的，返回的是列表，看不见内容</p>
<p> xpath表达式：</p>
<p>&#x2F;：表示是从根节点开始定位.表示一个层级</p>
<p>&#x2F;&#x2F;：表示的是多个层级】</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200204579.png" alt="image-20231231200204579"></p>
<p>&#x2F;&#x2F;div任意位置开始定位</p>
<p>属性定位：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200340011.png" alt="image-20231231200340011"></p>
<p>定位到的是属性为song的div，有可能多个，所以返回的也是列表</p>
<p>索引定位：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200542490.png" alt="image-20231231200542490"></p>
<p>这个div下有多个p标签</p>
<p>如果获取苏轼所对应的p标签</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200710670.png" alt="image-20231231200710670"></p>
<p>这样就可以了</p>
<p>注意！</p>
<p>注意！</p>
<p>这里的所以是从1开始的</p>
<p>如何取文本？</p>
<p>列：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101163043593.png" alt="image-20240101163043593"></p>
<p>如果我们想定位到第五个a标签可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&quot;test.html&quot;</span>)<span class="comment">#存在本地的html</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;//div[@class=&#x27;</span>tang<span class="string">&#x27;]//li[5]/a/text()&#x27;</span>) <span class="comment">#获取的是列表如果想要获取值直接在后面加入[0]</span></span><br><span class="line"><span class="built_in">print</span>(r) </span><br><span class="line"><span class="comment">#如果想获取度蜜月的话</span></span><br><span class="line">r=ree.xpath(<span class="string">&#x27;//div[class=&#x27;</span>tang<span class="string">&#x27;]//li[7]//text()&#x27;</span>)</span><br><span class="line"><span class="comment">#如果想获取一个标签下所有的内容包括子标签的话使用//</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;//div[@class=&#x27;</span>tang<span class="string">&#x27;]//text())</span></span><br><span class="line"><span class="string">             </span></span><br></pre></td></tr></table></figure>

<p>那么如何取属性值呢？</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101164246084.png" alt="image-20240101164246084"></p>
<p>取img下的src的属性值</p>
<p>可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&quot;test.html&quot;</span>)<span class="comment">#存在本地的html</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;//div[@class=&quot;song&quot;]/img/@src&#x27;</span>)<span class="comment">#返回的就是属性值</span></span><br></pre></td></tr></table></figure>

<h6 id="实战演练："><a href="#实战演练：" class="headerlink" title="实战演练："></a>实战演练：</h6><p>58二手房中相关的房源信息</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101164929438.png" alt="image-20240101164929438"></p>
<p>把房源的名字进行解析在进行持久话存储</p>
<p>标签的源码如下</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101171514037.png" alt="image-20240101171514037"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment">#实例化etree对象</span></span><br><span class="line"><span class="comment">#先爬取整张的页面数据</span></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://cn.58.com/ershoufang/&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text<span class="comment">#获取到源码数据</span></span><br><span class="line">tree=etree.HTML(page_text)<span class="comment">#加载到etree对象</span></span><br><span class="line"><span class="comment">#查看源码发现标题都在li下的a标签下所以我们可以把每个li给拿出来在对li在进行提取</span></span><br><span class="line">li_list=tree.xpath(<span class="string">&#x27;//section [@class=&quot;list&quot;]/div&#x27;</span>)</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;58同城title.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    title=li.xpath(<span class="string">&#x27;./a/div[2]//h3/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    fp.write(title+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(title+<span class="string">&#x27;打印成功&#x27;</span>)</span><br><span class="line">fp.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>解题的思路</p>
<p>首先</p>
<p>1.发现都在这个setion里面的</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101175106382.png" alt="image-20240101175106382"></p>
<p>下面的每一个div都是一个房源</p>
<p>我们可以先定位到section的div然后在遍历每个div</p>
<p>2.我们在一个的div的子div的第二个的img标签下的h3中发现了title</p>
<p>3.然后就可以提取了</p>
<p>代码这里就可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">title=li.xpath(<span class="string">&#x27;./a/div[2]//h3/text()&#x27;</span>)[<span class="number">0</span>]<span class="comment">#这个.也可以使用div</span></span><br></pre></td></tr></table></figure>

<p>我们还有简单不用思考获取xpath表达式的方法</p>
<p>找到需要用到源码的地方右键复制有个xpath</p>
<p>第二个案列：</p>
<p>解析下载图片案例</p>
<p>网站：<a target="_blank" rel="noopener" href="http://pic.netbian.com/4kmeinv/">4K美女壁纸_高清4K美女图片大全_彼岸图网 (netbian.com)</a></p>
<p>1.和糗图的那个类似不过就是换个方法来进行筛选</p>
<p>2.找到页面源码中的src的属性值</p>
<p>3.然后依次对src中的属性值进行get请求获得源码数据</p>
<p>插入一些知识</p>
<p>os创建文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定新文件夹的路径</span></span><br><span class="line">folder_path = <span class="string">&#x27;/path/to/new_folder&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查文件夹是否已经存在</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(folder_path):</span><br><span class="line">    <span class="comment"># 使用os.mkdir()函数创建文件夹</span></span><br><span class="line">    os.mkdir(folder_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;文件夹已创建&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;文件夹已存在&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>爬虫代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#创建文件夹</span></span><br><span class="line">filename = <span class="string">&#x27;meitu&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.mkdir(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;创建成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;文件夹已存在&#x27;</span>)</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;http://pic.netbian.com/4kmeinv/&#x27;</span></span><br><span class="line">response_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(response_text)</span><br><span class="line">list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_li:</span><br><span class="line">    new_url = <span class="string">&#x27;https://pic.netbian.com&#x27;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    detail_content = requests.get(url=new_url, headers=header).content</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span><span class="comment">#替换有/和：符号防止保存出错</span></span><br><span class="line">    path = os.path.join(filename, name)</span><br><span class="line">    <span class="built_in">print</span>(name, new_url, path)</span><br><span class="line">    fp = <span class="built_in">open</span>(path, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    fp.write(detail_content)</span><br><span class="line">    fp.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>修正解决文件名编码问题</p>
<p>通用中文乱码的解决方案</p>
<p>第一种方法</p>
<p>把响应数据设置成utf-8</p>
<p>格式如下：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101193424966.png" alt="image-20240101193424966"></p>
<p>第二种对出现乱码的地方先进行iso-8859-1编码然后在进行gbk解码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#创建文件夹</span></span><br><span class="line">filename = <span class="string">&#x27;meitu&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.mkdir(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;创建成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;文件夹已存在&#x27;</span>)</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;http://pic.netbian.com/4kmeinv/&#x27;</span></span><br><span class="line">response_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(response_text)</span><br><span class="line">list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_li:</span><br><span class="line">    new_url = <span class="string">&#x27;https://pic.netbian.com&#x27;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    detail_content = requests.get(url=new_url, headers=header).content</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span><span class="comment">#替换有/和：符号防止保存出错</span></span><br><span class="line">    img_name=name.encode(<span class="string">&#x27;iso-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">    path = os.path.join(filename, img_name)</span><br><span class="line">    <span class="built_in">print</span>(img_name, new_url, path)</span><br><span class="line">    fp = <span class="built_in">open</span>(path, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    fp.write(detail_content)</span><br><span class="line">    fp.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>已经解决</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101193922303.png" alt="image-20240101193922303"></p>
<p>项目分析</p>
<p>解析出所有城市的名称</p>
<p>任务爬取页面的全部名称<a target="_blank" rel="noopener" href="https://www.aqistudy.cn/historydata/">PM2.5历史数据_空气质量指数历史数据_中国空气质量在线监测分析平台历史数据 (aqistudy.cn)</a></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101195220708.png" alt="image-20240101195220708"></p>
<p>两个部分一个热门一个全部</p>
<p>热门的很简单</p>
<p>全部的解析</p>
<p>在bottom下有很多的ul标签</p>
<p>ul的第二个div保存着名称<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101203823916.png" alt="image-20240101203823916"></p>
<p>所以就可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_list=tree.xpath(<span class="string">&#x27;/html/body/div[3]/div/div[1]/div[2]/div[2]/ul/div[2]/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> city_all <span class="keyword">in</span> all_list:</span><br><span class="line">    allcity=city_all.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    all_city_list.append(allcity)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>全部的源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.aqistudy.cn/historydata/&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(page_text)</span><br><span class="line">host_city=[]</span><br><span class="line">all_city_list=[]</span><br><span class="line">host_list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;bottom&quot;]/ul/li&#x27;</span>)<span class="comment">#获取热门城市</span></span><br><span class="line"><span class="keyword">for</span> host_li <span class="keyword">in</span> host_list_li:</span><br><span class="line">    name=host_li.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]<span class="comment">#千万不要忘记加上0妇女会的是列表数据</span></span><br><span class="line">    <span class="comment">#在向列表中存储热门城市</span></span><br><span class="line">    host_city.append(name)</span><br><span class="line">    <span class="comment">#全部城市的获取</span></span><br><span class="line">all_list=tree.xpath(<span class="string">&#x27;/html/body/div[3]/div/div[1]/div[2]/div[2]/ul/div[2]/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> city_all <span class="keyword">in</span> all_list:</span><br><span class="line">    allcity=city_all.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    all_city_list.append(allcity)</span><br><span class="line"><span class="built_in">print</span>(host_city,<span class="built_in">len</span>(all_city_list))</span><br></pre></td></tr></table></figure>

<p>作业;</p>
<p>获取站长之家 的所有的简历模板</p>
<p> <a target="_blank" rel="noopener" href="https://sc.chinaz.com/jianli/biaoge.html">https://sc.chinaz.com/jianli/biaoge.html</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E5%A4%9A%E7%BA%BF%E7%A8%8B&%E5%AF%B9%E8%BF%9B%E7%A8%8B&%E5%BC%82%E6%AD%A5IO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E5%A4%9A%E7%BA%BF%E7%A8%8B&%E5%AF%B9%E8%BF%9B%E7%A8%8B&%E5%BC%82%E6%AD%A5IO/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-03 18:06:36" itemprop="dateModified" datetime="2024-01-03T18:06:36+08:00">2024-01-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="多线程-对进程-异步IO"><a href="#多线程-对进程-异步IO" class="headerlink" title="多线程&amp;对进程&amp;异步IO"></a>多线程&amp;对进程&amp;异步IO</h1><p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103175827289.png" alt="image-20240103175827289"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103175915904.png" alt="image-20240103175915904"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103180001817.png" alt="image-20240103180001817"></p>
<p>bound就是受限的意思</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103180108441.png" alt="image-20240103180108441"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103180518988.png" alt="image-20240103180518988"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103180538082.png" alt="image-20240103180538082"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240103180635053.png" alt="image-20240103180635053"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E5%92%8CPyExeJs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/01/29/1/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E5%92%8CPyExeJs/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-10 12:08:20" itemprop="dateModified" datetime="2024-01-10T12:08:20+08:00">2024-01-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="抓包工具和PyExeJs"><a href="#抓包工具和PyExeJs" class="headerlink" title="抓包工具和PyExeJs"></a>抓包工具和PyExeJs</h1><p>有的网站开启了抓包就进行无限的debug模式</p>
<p>打开开发者模式无限开启缓存</p>
<p>所以就需要使用抓包工具</p>
<p>或者打开开发者工具就页面进行返回上一页了</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110095443314.png" alt="image-20240110095443314"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110095426527.png" alt="image-20240110095426527"></p>
<p>思路</p>
<p>抓包后</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110101640946.png" alt="image-20240110101640946"></p>
<p>找到限制不让用F12的代码修改后在发包</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110101813223.png" alt="image-20240110101813223"></p>
<p>devtool就是 F12</p>
<p>去除主页面但是其他的也没面也会不让F12</p>
<p>所以最有效的解决方法</p>
<p>就是找到加载的js文件</p>
<p>然后使用工具进行绑定</p>
<p><strong><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110102717299.png" alt="image-20240110102717299"></strong></p>
<p>给他 绑定成空的文件</p>
<p>然后返回浏览器切记</p>
<p>用c+s+r进行刷新</p>
<p>还是不行就要清楚浏览器缓存</p>
<h1 id="PyExecjs"><a href="#PyExecjs" class="headerlink" title="PyExecjs"></a>PyExecjs</h1><p>他就pyhon的一个模块</p>
<p>解决js运行的问题</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110103259748.png" alt="image-20240110103259748"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110103310080.png" alt="image-20240110103310080"></p>
<p>很难理解</p>
<p>不涉及包全是算法基本全是原生的</p>
<p>没有第三方的js出现例如Jquery类似的</p>
<p>需要使用nodejs做运行环境</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110103656156.png" alt="image-20240110103656156"></p>
<p>安装</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110103932912.png" alt="image-20240110103932912"></p>
<p>安装<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110104348269.png" alt="image-20240110104348269"></p>
<p>配置环境</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110104520352.png" alt="image-20240110104520352"></p>
<p>代表成功了</p>
<p>这个模块主要帮助注我们完成js代码的运行</p>
<p>eval：执行js代码并且返回结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110110025660.png" alt="image-20240110110025660"></p>
<p>案列的实现</p>
<p>还是老朋友百度翻译</p>
<p>当我们改变参数查询的时候</p>
<p>发生了错误</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110113220174.png" alt="image-20240110113220174"></p>
<p>来回尝试和sign有关</p>
<p>只有找到了fn的运算的过程就可以破解了</p>
<p>发现应该是ajaxa所以去这里查找</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110113445129.png" alt="image-20240110113445129"></p>
<p>直接找太麻烦</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110113535880.png" alt="image-20240110113535880"></p>
<p>在栈这里找</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110113719122.png" alt="image-20240110113719122"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110113959796.png" alt="image-20240110113959796"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110114046277.png" alt="image-20240110114046277"></p>
<p>控制台调试的用法</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110114820986.png" alt="image-20240110114820986"></p>
<p>在右边进行标记</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110114839178.png" alt="image-20240110114839178"></p>
<p>然后在重新加载</p>
<p>就会停在这里</p>
<p>这里的getcur什么的责骂找都找不到</p>
<p>怀疑是闭包</p>
<p>内部再返回这个函数，然后有一个变量接受</p>
<p>然后在调用</p>
<p>然后右上角</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110115055414.png" alt="image-20240110115055414"></p>
<p>第三个是进一层</p>
<p>可以看见是怎么工作的</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110115138781.png" alt="image-20240110115138781"></p>
<p>发现就是这个东西</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110115329330.png" alt="image-20240110115329330"></p>
<p>找到了</p>
<p>所以这个M是定死的</p>
<p>为甚么用getcur什么什么的进入到d了呢因为</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110115445965.png" alt="image-20240110115445965"></p>
<p>在外面调用getCurdomain实际上就是调用闭包中的d的函数</p>
<p>然后再看sign的那个进行调试什么的以后进入这个函数‘</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110115658167.png" alt="image-20240110115658167"></p>
<p>直接看是非常的复杂</p>
<p>一个一个高没有必要</p>
<p>没有第三方的js的东西</p>
<p>不属于原生js的东西</p>
<p>所以就看可以使用pyyexecjs实现这个过程</p>
<p>把算法和主要用到的函数复制下来</p>
<p>感觉这才是入门</p>
<p>逆向很难</p>
<p>总结</p>
<p>找函数要设置断点</p>
<p>找变量去搜</p>
<p>运行出现window没有被定义</p>
<p>nodejs是后台运行js的环境没有window的对象</p>
<p>window对象是浏览器的</p>
<p>所以找到window</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110120646034.png" alt="image-20240110120646034"></p>
<p>直接把l复制到控制台运行</p>
<p>是gtk</p>
<p>那么window.gtk在哪里定义呢</p>
<p>再页面的源代码里面发现</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240110120808817.png" alt="image-20240110120808817"></p>
<p>所以这个就解决了</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="John Doe"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/WANGCHANGCHEN123/WANGCHANGCHEN123.github.io" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WANGCHANGCHEN123&#x2F;WANGCHANGCHEN123.github.io" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
