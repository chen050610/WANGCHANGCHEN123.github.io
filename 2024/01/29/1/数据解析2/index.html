<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="数据解析原理概念聚焦爬虫：爬取页面指定的内容。 数据分析分类基于正则基于bs46xpath(学习的重点)通用性强其它语言的爬虫也适用数据解析的大致原理指定局部的页面内容 例如我们提取的页面信息有可能在标签中，标签对应的属性中 也有可能在标签中的超链接中  1.进行指定标签的定位 2.标签对应的属性值进行提取（解析) 流程： 1指定url 2.发起请求 3.获取响应数据 4.数据解析 5.持久化储存">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%902/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="数据解析原理概念聚焦爬虫：爬取页面指定的内容。 数据分析分类基于正则基于bs46xpath(学习的重点)通用性强其它语言的爬虫也适用数据解析的大致原理指定局部的页面内容 例如我们提取的页面信息有可能在标签中，标签对应的属性中 也有可能在标签中的超链接中  1.进行指定标签的定位 2.标签对应的属性值进行提取（解析) 流程： 1指定url 2.发起请求 3.获取响应数据 4.数据解析 5.持久化储存">
<meta property="og:locale">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231140757216.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231151600316.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231152730742.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153148626.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153632747.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231154347839.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231155235042.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161155362.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161209460.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161815963.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161716409.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161850579.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231164118700.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231170252005.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231171653454.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172309956.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172849098.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231173104989.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174021277.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174400513.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174443172.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174522106.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174643158.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174944883.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231175718249.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231180005482.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231192536782.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195526560.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195559057.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200204579.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200340011.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200542490.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200710670.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101163043593.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101164246084.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101164929438.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101171514037.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101175106382.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101193424966.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101193922303.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101195220708.png">
<meta property="og:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101203823916.png">
<meta property="article:published_time" content="2024-01-29T08:15:30.315Z">
<meta property="article:modified_time" content="2024-01-02T02:07:58.950Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231140757216.png">

<link rel="canonical" href="http://example.com/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%902/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title> | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%902/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-29 16:15:30" itemprop="dateCreated datePublished" datetime="2024-01-29T16:15:30+08:00">2024-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-02 10:07:58" itemprop="dateModified" datetime="2024-01-02T10:07:58+08:00">2024-01-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h1><h5 id="原理概念"><a href="#原理概念" class="headerlink" title="原理概念"></a>原理概念</h5><p>聚焦爬虫：爬取页面指定的内容。</p>
<h5 id="数据分析分类"><a href="#数据分析分类" class="headerlink" title="数据分析分类"></a>数据分析分类</h5><h6 id="基于正则"><a href="#基于正则" class="headerlink" title="基于正则"></a>基于正则</h6><h6 id="基于bs46"><a href="#基于bs46" class="headerlink" title="基于bs46"></a>基于bs46</h6><h6 id="xpath-学习的重点-通用性强其它语言的爬虫也适用"><a href="#xpath-学习的重点-通用性强其它语言的爬虫也适用" class="headerlink" title="xpath(学习的重点)通用性强其它语言的爬虫也适用"></a>xpath(学习的重点)通用性强其它语言的爬虫也适用</h6><h5 id="数据解析的大致原理"><a href="#数据解析的大致原理" class="headerlink" title="数据解析的大致原理"></a>数据解析的大致原理</h5><p>指定局部的页面内容</p>
<p>例如我们提取的页面信息有可能在标签中，标签对应的属性中</p>
<p>也有可能在标签中的超链接中</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231140757216.png" alt="image-20231231140757216"></p>
<p>1.进行指定标签的定位</p>
<p>2.标签对应的属性值进行提取（解析)</p>
<p>流程：</p>
<p>1指定url</p>
<p>2.发起请求</p>
<p>3.获取响应数据</p>
<p>4.数据解析</p>
<p>5.持久化储存</p>
<h6 id="使用正则进行数据解析"><a href="#使用正则进行数据解析" class="headerlink" title="使用正则进行数据解析"></a>使用正则进行数据解析</h6><p>需求爬取糗事百科中囚徒板块下所有糗图的图片</p>
<p>这次需要爬取图片</p>
<p>如何爬取图片？</p>
<p>我们可以这样打开图片</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231151600316.png" alt="image-20231231151600316"></p>
<p>所以就可以利用url进行对文件资源的读写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231152730742.png" alt="image-20231231152730742"></p>
<p>之前读取的都是文本文件用text</p>
<p>这此时图片我们需要使用content获取二进制新形势的图片数据</p>
<p>text（字符串）context（二进制）json（对象） </p>
<p>代码如下</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153148626.png" alt="image-20231231153148626"></p>
<p>注意：在都写文件的时候需要使用wb：在 Python 中，打开文件时需要指定文件模式(mode)，以说明文件的打开方式和用途。其中，<code>w</code> 模式表示写入文本数据，而 <code>wb</code> 模式则表示写入二进制数据。在写入二进制数据时，需要使用 <code>wb</code> 模式，因为二进制数据中可能包含各种字节，例如 0x00、0x0A 等，这些字节在文本文件中有可能会被解释成特殊字符或控制字符，导致数据出现错误。通过使用 <code>wb</code> 模式打开文件，Python 会将数据原封不动地写入到文件中，而不做任何额外的转换或解释。这样可以确保写入的数据与原始数据完全一致，避免出现意外的错误。、</p>
<p>这样我们就成功返回二进制的图片数据</p>
<p>1：解题过程</p>
<p>没有这个网站，所以而我换了有一个网站再继续尝试</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231153632747.png" alt="image-20231231153632747"></p>
<p>第一步：获取整张数据</p>
<p>第二步：使用聚焦爬虫将页面中的图片进行爬取</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231154347839.png" alt="image-20231231154347839"></p>
<p>定位中图片发现与img图片的src的属性</p>
<p>我们需要把整张页面的img的src进行提取</p>
<p>然后再把每个图片给保存下来</p>
<p>此时就需要使用正则</p>
<p> 演示讲解</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231155235042.png" alt="image-20231231155235042"></p>
<p>构造正则</p>
<p>那是观察页面的源码发现一个大的div标签中有很多的小的div</p>
<p>每一个小的div中含有相同的上面源码的代码</p>
<p>所以就这样构造正则</p>
<p>利用正则组要使用re.findall()函数</p>
<p>re.findall()<code>是 Python 中</code>re&#96; 模块提供的一个函数，用于在字符串中查找匹配某个正则表达式的所有子串，并以列表的形式返回所有匹配结果。</p>
<p>具体来说，<code>re.findall(pattern, string)</code> 函数会在 <code>string</code> 字符串中查找所有与 <code>pattern</code> 正则表达式匹配的子串，并将它们全部存入一个列表中返回。如果没有匹配的结果，则返回空列表。</p>
<p>例如，下面的代码演示了如何使用 <code>re.findall()</code> 查找一个字符串中所有的数字：</p>
<p>[Python re.findall中正则表达式(.*?)和参数re.S使用_re</p>
<p>[]: </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36556893/article/details/89182067?ops_request_misc=&request_id=&biz_id=102&utm_term=re.findall()%E8%AF%AD%E6%B3%95re.S&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduweb~default-0-89182067.nonecase&spm=1018.2226.3001.4450">.findall()用法 re.s-CSDN博客</a></p>
<p>这里是详情用法</p>
<p>成功</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161155362.png" alt="image-20231231161155362"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161209460.png" alt="image-20231231161209460"></p>
<p>然后在对列表中每个连接进行get请求</p>
<p>然后就是对图片数据进行保存</p>
<p>我们先导入os模块创建文件夹</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161815963.png" alt="image-20231231161815963"></p>
<pre><code> 规定生成的图片名称
</code></pre>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161716409.png" alt="image-20231231161716409"></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231161850579.png" alt="image-20231231161850579"></p>
<p>然后后面的过程就知道了‘</p>
<p>在设置一个循环把多页的数据都给提出来</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231164118700.png" alt="image-20231231164118700"></p>
<p>over</p>
<h5 id="bs4（python独有的）进行数据-解析"><a href="#bs4（python独有的）进行数据-解析" class="headerlink" title="bs4（python独有的）进行数据 解析"></a>bs4（python独有的）进行数据 解析</h5><p>1.定位标签</p>
<p>2.提取标签</p>
<h6 id="bs4的原理"><a href="#bs4的原理" class="headerlink" title="bs4的原理"></a>bs4的原理</h6><p>1.实例化一个beatifulsoup对象，并且将页面源码数据加载到该对象中</p>
<p>2.通过调用beatifulsoup对象中相关的属性或者方法进行标签定位和数据提取</p>
<p>环境的配置：</p>
<p>pip install bs4</p>
<p>pip install lxml  	 	</p>
<p>如何实例化beatiful对象呢</p>
<p>from bs4 import BeautifulSoup</p>
<p>在操作的时候会遇到的问题</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231170252005.png" alt="image-20231231170252005"></p>
<p>把文件的名字bs4修改以下</p>
<p>因为他会在这个文件下寻找</p>
<p>对象的实例化：1.将本地的html页面加载到该对象中</p>
<p>可以发现我们打印是一个对象，对象之中存储的就是本地html的源码的内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br></pre></td></tr></table></figure>

<p>​							2将互联网上获取的页面源码加载到该对象中</p>
<p>这种方法便捷</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line"><span class="comment"># fp=open(&quot;hututu.html&quot;,&#x27;r&#x27;,encoding=&#x27;utf-8&#x27;)</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(fp,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">response=requests.get(url=url)</span><br><span class="line">page_txt=response.text</span><br><span class="line">soup=BeautifulSoup(page_txt,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup)</span><br></pre></td></tr></table></figure>

<p>结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231171653454.png" alt="image-20231231171653454"></p>
<p>提供用于数据解析的方法和属性：</p>
<p>1：soup.tagname:对象加上.标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.a)</span><br><span class="line"><span class="comment"># url=&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># response=requests.get(url=url)</span></span><br><span class="line"><span class="comment"># page_txt=response.text</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(page_txt,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br></pre></td></tr></table></figure>

<p>打印a标签的值，但是返回只是第一行</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172309956.png" alt="image-20231231172309956"></p>
<p>2.soup.find:和第一个类似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.p)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;p&#x27;</span>))</span><br><span class="line"><span class="comment"># url=&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment"># response=requests.get(url=url)</span></span><br><span class="line"><span class="comment"># page_txt=response.text</span></span><br><span class="line"><span class="comment"># soup=BeautifulSoup(page_txt,&#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>还有一种用法</p>
<p>属性定位</p>
<p>比如很多个div</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231172849098.png" alt="image-20231231172849098"></p>
<p>我想定位第二个div的话</p>
<p>可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;translate211217 trans-common special-subject&quot;</span>))</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231173104989.png" alt="image-20231231173104989"></p>
<p>class后面必须要加上_这样才能认为时属性值</p>
<p>3.soup.find.all:加载全部符合的标签</p>
<p>4.soup.select(“某种选择器”)例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#第一种实例化对象加载本地的html</span></span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&quot;hututu.html&quot;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">soup=BeautifulSoup(fp,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.select(<span class="string">&quot;.arrow&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174021277.png" alt="image-20231231174021277"></p>
<p>第二种用法（层层 的递归）</p>
<p>比如</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174400513.png" alt="image-20231231174400513"></p>
<p>我们想看a标签可以这么写</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174443172.png" alt="image-20231231174443172"></p>
<p>一共很多的a标签返回的时列表</p>
<p>我们可以</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174522106.png" alt="image-20231231174522106"></p>
<p>返回第一个标签</p>
<p>或者这么些空格表示多个层级</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174643158.png" alt="image-20231231174643158"></p>
<h6 id="获取标签中的文本数据："><a href="#获取标签中的文本数据：" class="headerlink" title="获取标签中的文本数据："></a>获取标签中的文本数据：</h6><p>soup.a.text&#x2F;string&#x2F;get_text()</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231174944883.png" alt="image-20231231174944883"></p>
<p>text string get_text()区别</p>
<p>text&#x2F;get_text()可以获取一个标签的所有文本内容，就比如div标签下有个a标签a标签下有内容，就可以获取的到</p>
<p>string：只可以获取该标签下的直系文本内容</p>
<h6 id="获取标签中的属性值"><a href="#获取标签中的属性值" class="headerlink" title="获取标签中的属性值"></a>获取标签中的属性值</h6><p>soup.a[‘href’]</p>
<p>获取a标签下的属性值的值</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231175718249.png" alt="image-20231231175718249"></p>
<h6 id="实际案列"><a href="#实际案列" class="headerlink" title="实际案列"></a>实际案列</h6><p>爬取三国演义小说所有章节标题和章节内容 </p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231180005482.png" alt="image-20231231180005482"></p>
<p>每一个章节都有一个a标签</p>
<p>解题思路</p>
<p>1.还是先获取整张页面</p>
<p>2.提取章节对应的名称和对应的href值</p>
<p>3.对href地址发送请求拿到详情页的所对应的章节内容提取</p>
<p>源码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.shicimingju.com/book/sanguoyanyi.html&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text</span><br><span class="line">soup=BeautifulSoup(page_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="comment">#定位到a标签在的地方</span></span><br><span class="line">list_a=soup.select(<span class="string">&#x27;.book-mulu &gt; ul &gt; li&#x27;</span>)</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;sanguo.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_a:</span><br><span class="line">    title=li.a.string</span><br><span class="line">    detail_url=<span class="string">&#x27;https://www.shicimingju.com&#x27;</span>+li.a[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对详情页发起请求,解析春章节内容</span></span><br><span class="line">    detail_text=requests.get(url=detail_url,headers=header).text<span class="comment">#观察源码发现内容保存在class=chapter_content的div标签下此时我们只需要该标签下的全部内容就可以</span></span><br><span class="line">    detail_soup=BeautifulSoup(detail_text,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    div_tag=detail_soup.find(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;chapter_content&quot;</span>)<span class="comment">#解析到章节的内容</span></span><br><span class="line">    content=div_tag.get_text()<span class="comment">#或者txt</span></span><br><span class="line">    fp.write(title+content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取成功&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>爬取的结果</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231192536782.png" alt="image-20231231192536782"></p>
<p>有些字符串编码问题，先不考虑了</p>
<h5 id="xpath解析（常用高效便捷通用）"><a href="#xpath解析（常用高效便捷通用）" class="headerlink" title="xpath解析（常用高效便捷通用）"></a>xpath解析（常用高效便捷通用）</h5><p>原理：</p>
<p>1.实例化一个ertee的对象,且需要将被解析的页面源码数据加载到该对象。</p>
<p>2.调用ertee对象中的xpath方法结合这xpath的表达式实现标签 的定位和内容的捕获。<br>环境的安装：</p>
<p>pip -install lxml (一款解析器)</p>
<p>如何实现实例化ertee的对象？\</p>
<p>from lxml import etree</p>
<p>1.还是本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">etree.parse(filepath)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2.可以将从互联网上个获取的源码家作家到该对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">etree.HTML(<span class="string">&#x27;page_text&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>本地的操练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&#x27;hututu.html&#x27;</span>)<span class="comment">#加载源码到该对象中&#x27;</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;/html/head/title&#x27;</span>)<span class="comment">#根据 层级关系进行定位</span></span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure>

<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195526560.png" alt="image-20231231195526560"></p>
<p>返回的是</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231195559057.png" alt="image-20231231195559057"></p>
<p>xpath是根据层级关系进行定位的，返回的是列表，看不见内容</p>
<p> xpath表达式：</p>
<p>&#x2F;：表示是从根节点开始定位.表示一个层级</p>
<p>&#x2F;&#x2F;：表示的是多个层级】</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200204579.png" alt="image-20231231200204579"></p>
<p>&#x2F;&#x2F;div任意位置开始定位</p>
<p>属性定位：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200340011.png" alt="image-20231231200340011"></p>
<p>定位到的是属性为song的div，有可能多个，所以返回的也是列表</p>
<p>索引定位：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200542490.png" alt="image-20231231200542490"></p>
<p>这个div下有多个p标签</p>
<p>如果获取苏轼所对应的p标签</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20231231200710670.png" alt="image-20231231200710670"></p>
<p>这样就可以了</p>
<p>注意！</p>
<p>注意！</p>
<p>这里的所以是从1开始的</p>
<p>如何取文本？</p>
<p>列：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101163043593.png" alt="image-20240101163043593"></p>
<p>如果我们想定位到第五个a标签可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&quot;test.html&quot;</span>)<span class="comment">#存在本地的html</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;//div[@class=&#x27;</span>tang<span class="string">&#x27;]//li[5]/a/text()&#x27;</span>) <span class="comment">#获取的是列表如果想要获取值直接在后面加入[0]</span></span><br><span class="line"><span class="built_in">print</span>(r) </span><br><span class="line"><span class="comment">#如果想获取度蜜月的话</span></span><br><span class="line">r=ree.xpath(<span class="string">&#x27;//div[class=&#x27;</span>tang<span class="string">&#x27;]//li[7]//text()&#x27;</span>)</span><br><span class="line"><span class="comment">#如果想获取一个标签下所有的内容包括子标签的话使用//</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;//div[@class=&#x27;</span>tang<span class="string">&#x27;]//text())</span></span><br><span class="line"><span class="string">             </span></span><br></pre></td></tr></table></figure>

<p>那么如何取属性值呢？</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101164246084.png" alt="image-20240101164246084"></p>
<p>取img下的src的属性值</p>
<p>可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.parse(<span class="string">&quot;test.html&quot;</span>)<span class="comment">#存在本地的html</span></span><br><span class="line">r=tree.xpath(<span class="string">&#x27;//div[@class=&quot;song&quot;]/img/@src&#x27;</span>)<span class="comment">#返回的就是属性值</span></span><br></pre></td></tr></table></figure>

<h6 id="实战演练："><a href="#实战演练：" class="headerlink" title="实战演练："></a>实战演练：</h6><p>58二手房中相关的房源信息</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101164929438.png" alt="image-20240101164929438"></p>
<p>把房源的名字进行解析在进行持久话存储</p>
<p>标签的源码如下</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101171514037.png" alt="image-20240101171514037"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment">#实例化etree对象</span></span><br><span class="line"><span class="comment">#先爬取整张的页面数据</span></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://cn.58.com/ershoufang/&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text<span class="comment">#获取到源码数据</span></span><br><span class="line">tree=etree.HTML(page_text)<span class="comment">#加载到etree对象</span></span><br><span class="line"><span class="comment">#查看源码发现标题都在li下的a标签下所以我们可以把每个li给拿出来在对li在进行提取</span></span><br><span class="line">li_list=tree.xpath(<span class="string">&#x27;//section [@class=&quot;list&quot;]/div&#x27;</span>)</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;58同城title.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    title=li.xpath(<span class="string">&#x27;./a/div[2]//h3/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    fp.write(title+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(title+<span class="string">&#x27;打印成功&#x27;</span>)</span><br><span class="line">fp.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>解题的思路</p>
<p>首先</p>
<p>1.发现都在这个setion里面的</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101175106382.png" alt="image-20240101175106382"></p>
<p>下面的每一个div都是一个房源</p>
<p>我们可以先定位到section的div然后在遍历每个div</p>
<p>2.我们在一个的div的子div的第二个的img标签下的h3中发现了title</p>
<p>3.然后就可以提取了</p>
<p>代码这里就可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">title=li.xpath(<span class="string">&#x27;./a/div[2]//h3/text()&#x27;</span>)[<span class="number">0</span>]<span class="comment">#这个.也可以使用div</span></span><br></pre></td></tr></table></figure>

<p>我们还有简单不用思考获取xpath表达式的方法</p>
<p>找到需要用到源码的地方右键复制有个xpath</p>
<p>第二个案列：</p>
<p>解析下载图片案例</p>
<p>网站：<a target="_blank" rel="noopener" href="http://pic.netbian.com/4kmeinv/">4K美女壁纸_高清4K美女图片大全_彼岸图网 (netbian.com)</a></p>
<p>1.和糗图的那个类似不过就是换个方法来进行筛选</p>
<p>2.找到页面源码中的src的属性值</p>
<p>3.然后依次对src中的属性值进行get请求获得源码数据</p>
<p>插入一些知识</p>
<p>os创建文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定新文件夹的路径</span></span><br><span class="line">folder_path = <span class="string">&#x27;/path/to/new_folder&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查文件夹是否已经存在</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(folder_path):</span><br><span class="line">    <span class="comment"># 使用os.mkdir()函数创建文件夹</span></span><br><span class="line">    os.mkdir(folder_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;文件夹已创建&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;文件夹已存在&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>爬虫代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#创建文件夹</span></span><br><span class="line">filename = <span class="string">&#x27;meitu&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.mkdir(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;创建成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;文件夹已存在&#x27;</span>)</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;http://pic.netbian.com/4kmeinv/&#x27;</span></span><br><span class="line">response_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(response_text)</span><br><span class="line">list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_li:</span><br><span class="line">    new_url = <span class="string">&#x27;https://pic.netbian.com&#x27;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    detail_content = requests.get(url=new_url, headers=header).content</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span><span class="comment">#替换有/和：符号防止保存出错</span></span><br><span class="line">    path = os.path.join(filename, name)</span><br><span class="line">    <span class="built_in">print</span>(name, new_url, path)</span><br><span class="line">    fp = <span class="built_in">open</span>(path, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    fp.write(detail_content)</span><br><span class="line">    fp.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>修正解决文件名编码问题</p>
<p>通用中文乱码的解决方案</p>
<p>第一种方法</p>
<p>把响应数据设置成utf-8</p>
<p>格式如下：</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101193424966.png" alt="image-20240101193424966"></p>
<p>第二种对出现乱码的地方先进行iso-8859-1编码然后在进行gbk解码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#创建文件夹</span></span><br><span class="line">filename = <span class="string">&#x27;meitu&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    os.mkdir(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;创建成功&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;文件夹已存在&#x27;</span>)</span><br><span class="line"></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;http://pic.netbian.com/4kmeinv/&#x27;</span></span><br><span class="line">response_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(response_text)</span><br><span class="line">list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;slist&quot;]/ul/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> list_li:</span><br><span class="line">    new_url = <span class="string">&#x27;https://pic.netbian.com&#x27;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    detail_content = requests.get(url=new_url, headers=header).content</span><br><span class="line">    name = li.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27;.jpg&#x27;</span><span class="comment">#替换有/和：符号防止保存出错</span></span><br><span class="line">    img_name=name.encode(<span class="string">&#x27;iso-8859-1&#x27;</span>).decode(<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">    path = os.path.join(filename, img_name)</span><br><span class="line">    <span class="built_in">print</span>(img_name, new_url, path)</span><br><span class="line">    fp = <span class="built_in">open</span>(path, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">    fp.write(detail_content)</span><br><span class="line">    fp.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>已经解决</p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101193922303.png" alt="image-20240101193922303"></p>
<p>项目分析</p>
<p>解析出所有城市的名称</p>
<p>任务爬取页面的全部名称<a target="_blank" rel="noopener" href="https://www.aqistudy.cn/historydata/">PM2.5历史数据_空气质量指数历史数据_中国空气质量在线监测分析平台历史数据 (aqistudy.cn)</a></p>
<p><img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101195220708.png" alt="image-20240101195220708"></p>
<p>两个部分一个热门一个全部</p>
<p>热门的很简单</p>
<p>全部的解析</p>
<p>在bottom下有很多的ul标签</p>
<p>ul的第二个div保存着名称<img src="https://hututu345.oss-cn-beijing.aliyuncs.com/typora/image-20240101203823916.png" alt="image-20240101203823916"></p>
<p>所以就可以这么写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">all_list=tree.xpath(<span class="string">&#x27;/html/body/div[3]/div/div[1]/div[2]/div[2]/ul/div[2]/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> city_all <span class="keyword">in</span> all_list:</span><br><span class="line">    allcity=city_all.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    all_city_list.append(allcity)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>全部的源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.aqistudy.cn/historydata/&#x27;</span></span><br><span class="line">page_text=requests.get(url=url,headers=header).text</span><br><span class="line">tree=etree.HTML(page_text)</span><br><span class="line">host_city=[]</span><br><span class="line">all_city_list=[]</span><br><span class="line">host_list_li=tree.xpath(<span class="string">&#x27;//div[@class=&quot;bottom&quot;]/ul/li&#x27;</span>)<span class="comment">#获取热门城市</span></span><br><span class="line"><span class="keyword">for</span> host_li <span class="keyword">in</span> host_list_li:</span><br><span class="line">    name=host_li.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]<span class="comment">#千万不要忘记加上0妇女会的是列表数据</span></span><br><span class="line">    <span class="comment">#在向列表中存储热门城市</span></span><br><span class="line">    host_city.append(name)</span><br><span class="line">    <span class="comment">#全部城市的获取</span></span><br><span class="line">all_list=tree.xpath(<span class="string">&#x27;/html/body/div[3]/div/div[1]/div[2]/div[2]/ul/div[2]/li&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> city_all <span class="keyword">in</span> all_list:</span><br><span class="line">    allcity=city_all.xpath(<span class="string">&#x27;./a/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    all_city_list.append(allcity)</span><br><span class="line"><span class="built_in">print</span>(host_city,<span class="built_in">len</span>(all_city_list))</span><br></pre></td></tr></table></figure>

<p>作业;</p>
<p>获取站长之家 的所有的简历模板</p>
<p> <a target="_blank" rel="noopener" href="https://sc.chinaz.com/jianli/biaoge.html">https://sc.chinaz.com/jianli/biaoge.html</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/01/29/1/%E5%A4%9A%E7%BA%BF%E7%A8%8B&%E5%AF%B9%E8%BF%9B%E7%A8%8B&%E5%BC%82%E6%AD%A5IO/" rel="prev" title="">
      <i class="fa fa-chevron-left"></i> 
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/29/1/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">数据解析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8E%9F%E7%90%86%E6%A6%82%E5%BF%B5"><span class="nav-number">1.0.0.0.1.</span> <span class="nav-text">原理概念</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%88%86%E7%B1%BB"><span class="nav-number">1.0.0.0.2.</span> <span class="nav-text">数据分析分类</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%AD%A3%E5%88%99"><span class="nav-number">1.0.0.0.2.1.</span> <span class="nav-text">基于正则</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Ebs46"><span class="nav-number">1.0.0.0.2.2.</span> <span class="nav-text">基于bs46</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#xpath-%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%87%8D%E7%82%B9-%E9%80%9A%E7%94%A8%E6%80%A7%E5%BC%BA%E5%85%B6%E5%AE%83%E8%AF%AD%E8%A8%80%E7%9A%84%E7%88%AC%E8%99%AB%E4%B9%9F%E9%80%82%E7%94%A8"><span class="nav-number">1.0.0.0.2.3.</span> <span class="nav-text">xpath(学习的重点)通用性强其它语言的爬虫也适用</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90%E7%9A%84%E5%A4%A7%E8%87%B4%E5%8E%9F%E7%90%86"><span class="nav-number">1.0.0.0.3.</span> <span class="nav-text">数据解析的大致原理</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%AD%A3%E5%88%99%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90"><span class="nav-number">1.0.0.0.3.1.</span> <span class="nav-text">使用正则进行数据解析</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#bs4%EF%BC%88python%E7%8B%AC%E6%9C%89%E7%9A%84%EF%BC%89%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE-%E8%A7%A3%E6%9E%90"><span class="nav-number">1.0.0.0.4.</span> <span class="nav-text">bs4（python独有的）进行数据 解析</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#bs4%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-number">1.0.0.0.4.1.</span> <span class="nav-text">bs4的原理</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E4%B8%AD%E7%9A%84%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%EF%BC%9A"><span class="nav-number">1.0.0.0.4.2.</span> <span class="nav-text">获取标签中的文本数据：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E4%B8%AD%E7%9A%84%E5%B1%9E%E6%80%A7%E5%80%BC"><span class="nav-number">1.0.0.0.4.3.</span> <span class="nav-text">获取标签中的属性值</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E9%99%85%E6%A1%88%E5%88%97"><span class="nav-number">1.0.0.0.4.4.</span> <span class="nav-text">实际案列</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#xpath%E8%A7%A3%E6%9E%90%EF%BC%88%E5%B8%B8%E7%94%A8%E9%AB%98%E6%95%88%E4%BE%BF%E6%8D%B7%E9%80%9A%E7%94%A8%EF%BC%89"><span class="nav-number">1.0.0.0.5.</span> <span class="nav-text">xpath解析（常用高效便捷通用）</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AE%9E%E6%88%98%E6%BC%94%E7%BB%83%EF%BC%9A"><span class="nav-number">1.0.0.0.5.1.</span> <span class="nav-text">实战演练：</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="John Doe"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/WANGCHANGCHEN123/WANGCHANGCHEN123.github.io" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WANGCHANGCHEN123&#x2F;WANGCHANGCHEN123.github.io" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
